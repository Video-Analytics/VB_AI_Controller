{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "promising-digit",
   "metadata": {},
   "source": [
    "## NeMo Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incredible-salon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nemo_toolkit[all]\n",
      "  Cloning https://github.com/NVIDIA/NeMo.git (to revision main) to c:\\users\\blob2\\appdata\\local\\temp\\pip-install-nfd40z9q\\nemo-toolkit_55d8ad25bd8040d896248d9cabeec781\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.20.1)\n",
      "Requirement already satisfied: onnx>=1.7.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.8.1)\n",
      "Collecting pytorch-lightning>=1.3.0\n",
      "  Downloading pytorch_lightning-1.3.5-py3-none-any.whl (808 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (2.8.1)\n",
      "Requirement already satisfied: torch in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.7.1)\n",
      "Requirement already satisfied: wget in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (3.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.12.1)\n",
      "Requirement already satisfied: ruamel.yaml in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.16.12)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.24.1)\n",
      "Collecting omegaconf<2.1.0,>=2.0.5\n",
      "  Using cached omegaconf-2.0.6-py3-none-any.whl (36 kB)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/NVIDIA/NeMo.git 'C:\\Users\\Blob2\\AppData\\Local\\Temp\\pip-install-nfd40z9q\\nemo-toolkit_55d8ad25bd8040d896248d9cabeec781'\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "detectron2 0.4 requires black==21.4b2, but you have black 19.10b0 which is incompatible.\n",
      "detectron2 0.4 requires hydra-core>=1.1.0rc1, but you have hydra-core 1.0.6 which is incompatible.\n",
      "detectron2 0.4 requires omegaconf>=2.1.0rc1, but you have omegaconf 2.0.6 which is incompatible.\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Blob2\\.conda\\envs\\vbank\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: hydra-core>=1.0.4 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from nemo_toolkit[all]) (1.1.0rc1)\n",
      "Requirement already satisfied: transformers>=4.0.1 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from nemo_toolkit[all]) (4.2.2)\n",
      "Requirement already satisfied: sentencepiece<1.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.1.91)\n",
      "Requirement already satisfied: webdataset<=0.1.62,>=0.1.48 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.1.48)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from nemo_toolkit[all]) (4.61.0)\n",
      "Requirement already satisfied: opencc in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.1.1)\n",
      "Requirement already satisfied: pangu in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (4.0.6.1)\n",
      "Requirement already satisfied: jieba in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.42.1)\n",
      "Requirement already satisfied: numba in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.51.2)\n",
      "Collecting black==19.10b0\n",
      "  Using cached black-19.10b0-py36-none-any.whl (97 kB)\n",
      "Requirement already satisfied: isort[requirements]<5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (4.3.21)\n",
      "Requirement already satisfied: parameterized in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.8.1)\n",
      "Requirement already satisfied: pytest in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (6.2.2)\n",
      "Requirement already satisfied: pytest-runner in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (5.3.0)\n",
      "Requirement already satisfied: sphinx in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (3.5.0)\n",
      "Requirement already satisfied: sphinxcontrib-bibtex in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (2.1.4)\n",
      "Requirement already satisfied: wandb in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.10.19)\n",
      "Requirement already satisfied: braceexpand in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.1.6)\n",
      "Requirement already satisfied: editdistance in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.5.3)\n",
      "Requirement already satisfied: frozendict in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.2)\n",
      "Requirement already satisfied: inflect in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (5.0.2)\n",
      "Requirement already satisfied: kaldi-io in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.9.4)\n",
      "Requirement already satisfied: librosa in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.8.0)\n",
      "Requirement already satisfied: marshmallow in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (3.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (20.9)\n",
      "Requirement already satisfied: soundfile in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.10.3.post1)\n",
      "Requirement already satisfied: sox in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.4.1)\n",
      "Requirement already satisfied: unidecode in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.2.0)\n",
      "Requirement already satisfied: kaldi-python-io in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.2.1)\n",
      "Requirement already satisfied: kaldiio in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (2.17.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.2.2)\n",
      "Requirement already satisfied: g2p_en in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (2.1.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.24.1)\n",
      "Requirement already satisfied: pyannote.core in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (4.1)\n",
      "Requirement already satisfied: pyannote.metrics in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (3.0.1)\n",
      "Collecting pyamg\n",
      "  Downloading pyamg-4.1.0.tar.gz (749 kB)\n",
      "Requirement already satisfied: torch-stft in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.1.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (7.6.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from nemo_toolkit[all]) (3.4.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (8.1.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.8.2)\n",
      "Requirement already satisfied: boto3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.17.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (3.1.0)\n",
      "Requirement already satisfied: youtokentome>=1.0.5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.0.6)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: gdown in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (3.12.2)\n",
      "Collecting megatron-lm==2.2.0\n",
      "  Downloading megatron_lm-2.2.0-py3-none-any.whl (171 kB)\n",
      "Requirement already satisfied: sacrebleu[ja] in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (1.5.0)\n",
      "Requirement already satisfied: sacremoses>=0.0.43 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.0.43)\n",
      "Requirement already satisfied: pypinyin in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.40.0)\n",
      "Requirement already satisfied: attrdict in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: pystoi in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.3.3)\n",
      "Requirement already satisfied: pesq in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (0.0.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nemo_toolkit[all]) (3.5)\n",
      "Requirement already satisfied: regex in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from nemo_toolkit[all]) (2021.4.4)\n",
      "Requirement already satisfied: click>=6.5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from black==19.10b0->nemo_toolkit[all]) (7.1.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from black==19.10b0->nemo_toolkit[all]) (1.4.4)\n",
      "Requirement already satisfied: toml>=0.9.4 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from black==19.10b0->nemo_toolkit[all]) (0.10.2)\n",
      "Requirement already satisfied: pathspec<1,>=0.6 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from black==19.10b0->nemo_toolkit[all]) (0.8.1)\n",
      "Requirement already satisfied: typed-ast>=1.4.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from black==19.10b0->nemo_toolkit[all]) (1.4.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from black==19.10b0->nemo_toolkit[all]) (20.3.0)\n",
      "Requirement already satisfied: pybind11 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from megatron-lm==2.2.0->nemo_toolkit[all]) (2.6.2)\n",
      "Requirement already satisfied: six in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from megatron-lm==2.2.0->nemo_toolkit[all]) (1.15.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from hydra-core>=1.0.4->nemo_toolkit[all]) (4.8)\n",
      "Collecting hydra-core>=1.0.4\n",
      "  Using cached hydra_core-1.0.6-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from hydra-core>=1.0.4->nemo_toolkit[all]) (5.1.4)\n",
      "Requirement already satisfied: pip-api in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from isort[requirements]<5->nemo_toolkit[all]) (0.0.18)\n",
      "Requirement already satisfied: pipreqs in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from isort[requirements]<5->nemo_toolkit[all]) (0.4.10)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from omegaconf<2.1.0,>=2.0.5->nemo_toolkit[all]) (3.7.4.3)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from omegaconf<2.1.0,>=2.0.5->nemo_toolkit[all]) (5.4.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from onnx>=1.7.0->nemo_toolkit[all]) (3.17.1)\n",
      "Collecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting torchmetrics>=0.2.0\n",
      "  Downloading torchmetrics-0.3.2-py3-none-any.whl (274 kB)\n",
      "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2021.5.0-py3-none-any.whl (111 kB)\n",
      "Requirement already satisfied: future>=0.17.1 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from pytorch-lightning>=1.3.0->nemo_toolkit[all]) (0.18.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (3.7.3)\n",
      "Requirement already satisfied: requests in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (2.22.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sacremoses>=0.0.43->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (53.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (0.12.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (1.30.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (3.3.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (1.38.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (2020.12.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from transformers>=4.0.1->nemo_toolkit[all]) (3.0.12)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from transformers>=4.0.1->nemo_toolkit[all]) (0.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (5.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (3.0.1)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.8 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from boto3->nemo_toolkit[all]) (1.20.8)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from boto3->nemo_toolkit[all]) (0.3.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from boto3->nemo_toolkit[all]) (0.10.0)\n",
      "Requirement already satisfied: distance>=0.1.3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from g2p_en->nemo_toolkit[all]) (0.1.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from importlib-resources->hydra-core>=1.0.4->nemo_toolkit[all]) (3.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipywidgets->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipywidgets->nemo_toolkit[all]) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipywidgets->nemo_toolkit[all]) (7.20.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipywidgets->nemo_toolkit[all]) (5.1.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipywidgets->nemo_toolkit[all]) (5.4.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipywidgets->nemo_toolkit[all]) (5.0.5)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (6.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[all]) (6.1.11)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (3.0.16)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (2.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.18.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (4.4.2)\n",
      "Requirement already satisfied: backcall in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.4.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.8.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (4.7.1)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (0.17.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->nemo_toolkit[all]) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (6.2.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (6.0.7)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (20.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (22.0.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.9.2)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.9.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets->nemo_toolkit[all]) (300)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.1.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from librosa->nemo_toolkit[all]) (2.1.9)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from librosa->nemo_toolkit[all]) (1.3.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from librosa->nemo_toolkit[all]) (0.2.2)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from numba->nemo_toolkit[all]) (0.34.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from scikit-learn->nemo_toolkit[all]) (2.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib->nemo_toolkit[all]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib->nemo_toolkit[all]) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from matplotlib->nemo_toolkit[all]) (2.4.7)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (3.3.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.4.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.2)\n",
      "Requirement already satisfied: async-generator in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->nemo_toolkit[all]) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pandas->nemo_toolkit[all]) (2021.1)\n",
      "Requirement already satisfied: pip in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from pip-api->isort[requirements]<5->nemo_toolkit[all]) (21.0.1)\n",
      "Requirement already satisfied: yarg in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pipreqs->isort[requirements]<5->nemo_toolkit[all]) (0.1.9)\n",
      "Requirement already satisfied: docopt in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pipreqs->isort[requirements]<5->nemo_toolkit[all]) (0.6.2)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pytest->nemo_toolkit[all]) (1.4.0)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pytest->nemo_toolkit[all]) (0.13.1)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pytest->nemo_toolkit[all]) (1.1.1)\n",
      "Requirement already satisfied: py>=1.8.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pytest->nemo_toolkit[all]) (1.10.0)\n",
      "Requirement already satisfied: simplejson>=3.8.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pyannote.core->nemo_toolkit[all]) (3.17.2)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pyannote.core->nemo_toolkit[all]) (2.3.0)\n",
      "Requirement already satisfied: sympy>=1.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pyannote.metrics->nemo_toolkit[all]) (1.7.1)\n",
      "Requirement already satisfied: pyannote.database>=4.0.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pyannote.metrics->nemo_toolkit[all]) (4.0.4)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from pyannote.metrics->nemo_toolkit[all]) (0.8.9)\n",
      "Requirement already satisfied: typer[all]>=0.2.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (0.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sympy>=1.1->pyannote.metrics->nemo_toolkit[all]) (1.2.1)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from typer[all]>=0.2.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[all]) (1.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.0->nemo_toolkit[all]) (1.7.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from ruamel.yaml->nemo_toolkit[all]) (0.2.2)\n",
      "Requirement already satisfied: portalocker in c:\\users\\blob2\\appdata\\roaming\\python\\python38\\site-packages (from sacrebleu[ja]->nemo_toolkit[all]) (2.3.0)\n",
      "Collecting mecab-python3==1.0.3\n",
      "  Using cached mecab_python3-1.0.3-cp38-cp38-win_amd64.whl (509 kB)\n",
      "Collecting ipadic<2.0,>=1.0\n",
      "  Using cached ipadic-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (0.7.12)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (1.0.2)\n",
      "Requirement already satisfied: docutils>=0.12 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (0.16)\n",
      "Requirement already satisfied: imagesize in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (1.2.0)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (2.9.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinx->nemo_toolkit[all]) (1.1.4)\n",
      "Requirement already satisfied: pybtex-docutils>=0.2.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (1.0.0)\n",
      "Requirement already satisfied: pybtex>=0.20 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from sphinxcontrib-bibtex->nemo_toolkit[all]) (0.24.0)\n",
      "Requirement already satisfied: latexcodec>=1.0.4 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pybtex>=0.20->sphinxcontrib-bibtex->nemo_toolkit[all]) (2.0.1)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (3.1.13)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (5.8.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (2.3)\n",
      "Requirement already satisfied: configparser>=3.8.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (5.0.1)\n",
      "Requirement already satisfied: pathtools in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (0.1.2)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (0.20.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (1.0.1)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from wandb->nemo_toolkit[all]) (3.5.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from GitPython>=1.0.0->wandb->nemo_toolkit[all]) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->nemo_toolkit[all]) (3.0.5)\n",
      "Building wheels for collected packages: nemo-toolkit, pyamg\n",
      "  Building wheel for nemo-toolkit (setup.py): started\n",
      "  Building wheel for nemo-toolkit (setup.py): finished with status 'done'\n",
      "  Created wheel for nemo-toolkit: filename=nemo_toolkit-1.0.1-py3-none-any.whl size=1154441 sha256=3f98c4ce17850048311eca93df80c8701821e2ce98b3fc493964886e7b6d2797\n",
      "  Stored in directory: C:\\Users\\Blob2\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-2f1erlhr\\wheels\\76\\8c\\14\\f1ad178881c7340cf8e629686593904531249cf8b2de155d8c\n",
      "  Building wheel for pyamg (setup.py): started\n",
      "  Building wheel for pyamg (setup.py): finished with status 'done'\n",
      "  Created wheel for pyamg: filename=pyamg-4.1.0-cp38-cp38-win_amd64.whl size=1374990 sha256=3a7bfe0482ee9cff25c277745997681cbb318245f06a1a9670499dc01d93a704\n",
      "  Stored in directory: c:\\users\\blob2\\appdata\\local\\pip\\cache\\wheels\\d6\\67\\e8\\e04fec7778a9c5fb9484c231c2047e44da74a5cbd524989e5d\n",
      "Successfully built nemo-toolkit pyamg\n",
      "Installing collected packages: fsspec, torchmetrics, tensorboard, pyDeprecate, omegaconf, pytorch-lightning, mecab-python3, ipadic, hydra-core, pyamg, nemo-toolkit, megatron-lm, black\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.8.5\n",
      "    Uninstalling fsspec-0.8.5:\n",
      "      Successfully uninstalled fsspec-0.8.5\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.1.0rc1\n",
      "    Uninstalling omegaconf-2.1.0rc1:\n",
      "      Successfully uninstalled omegaconf-2.1.0rc1\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.1.5\n",
      "    Uninstalling pytorch-lightning-1.1.5:\n",
      "      Successfully uninstalled pytorch-lightning-1.1.5\n",
      "  Attempting uninstall: hydra-core\n",
      "    Found existing installation: hydra-core 1.1.0rc1\n",
      "    Uninstalling hydra-core-1.1.0rc1:\n",
      "      Successfully uninstalled hydra-core-1.1.0rc1\n",
      "  Attempting uninstall: nemo-toolkit\n",
      "    Found existing installation: nemo-toolkit 1.0.0rc1\n",
      "    Uninstalling nemo-toolkit-1.0.0rc1:\n",
      "      Successfully uninstalled nemo-toolkit-1.0.0rc1\n",
      "  Attempting uninstall: megatron-lm\n",
      "    Found existing installation: megatron-lm 1.1.5\n",
      "    Uninstalling megatron-lm-1.1.5:\n",
      "      Successfully uninstalled megatron-lm-1.1.5\n",
      "  Attempting uninstall: black\n",
      "    Found existing installation: black 21.4b2\n",
      "    Uninstalling black-21.4b2:\n",
      "      Successfully uninstalled black-21.4b2\n",
      "Successfully installed black-19.10b0 fsspec-2021.5.0 hydra-core-1.0.6 ipadic-1.0.0 mecab-python3-1.0.3 megatron-lm-2.2.0 nemo-toolkit-1.0.1 omegaconf-2.1.0.dev22 pyDeprecate-0.3.0 pyamg-4.1.0 pytorch-lightning-1.3.5 tensorboard-2.4.1 torchmetrics-0.3.2\n"
     ]
    }
   ],
   "source": [
    "BRANCH = 'main'\n",
    "!pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "described-journey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "increased-combat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PretrainedModelInfo(pretrained_model_name='ContextNet-192-WPE-1024-8x-Stride', description='ContextNet initial implementation with CTC loss model trained on the Librispeech corpus and achieves a WER of 10.09% on test-other and 10.11% on dev-other.', location='https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/ContextNet-192-WPE-1024-8x-Stride.nemo', class_=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list = nemo_asr.models.EncDecCTCModelBPE.list_available_models()\n",
    "for model in model_list:\n",
    "    print(model)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "potential-appearance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-06-09 11:57:52 cloud:56] Found existing object C:\\Users\\Blob2\\.cache\\torch\\NeMo\\NeMo_1.0.0rc1\\QuartzNet15x5Base-En\\00869f9c89b8393ca3de640e0c536bd2\\QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2021-06-09 11:57:52 cloud:62] Re-using file from: C:\\Users\\Blob2\\.cache\\torch\\NeMo\\NeMo_1.0.0rc1\\QuartzNet15x5Base-En\\00869f9c89b8393ca3de640e0c536bd2\\QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2021-06-09 11:57:52 common:595] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-06-09 11:57:53 features:239] PADDING: 16\n",
      "[NeMo I 2021-06-09 11:57:53 features:255] STFT using torch\n",
      "[NeMo I 2021-06-09 11:57:57 modelPT:413] Model EncDecCTCModel was successfully restored from C:\\Users\\Blob2\\.cache\\torch\\NeMo\\NeMo_1.0.0rc1\\QuartzNet15x5Base-En\\00869f9c89b8393ca3de640e0c536bd2\\QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2021-06-09 11:57:57 cloud:56] Found existing object C:\\Users\\Blob2\\.cache\\torch\\NeMo\\NeMo_1.0.0rc1\\Punctuation_Capitalization_with_BERT\\963746287f3f56c17e788b02881e7447\\Punctuation_Capitalization_with_BERT.nemo.\n",
      "[NeMo I 2021-06-09 11:57:57 cloud:62] Re-using file from: C:\\Users\\Blob2\\.cache\\torch\\NeMo\\NeMo_1.0.0rc1\\Punctuation_Capitalization_with_BERT\\963746287f3f56c17e788b02881e7447\\Punctuation_Capitalization_with_BERT.nemo\n",
      "[NeMo I 2021-06-09 11:57:57 common:595] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2021-06-09 11:58:01 modelPT:145] Please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    shuffle: true\n",
      "    num_samples: -1\n",
      "    batch_size: 64\n",
      "    \n",
      "[NeMo W 2021-06-09 11:58:01 modelPT:152] Please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    shuffle: false\n",
      "    num_samples: -1\n",
      "    batch_size: 64\n",
      "    \n",
      "[NeMo W 2021-06-09 11:58:01 modelPT:1224] World size can only be set by PyTorch Lightning Trainer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-06-09 11:58:06 modelPT:413] Model PunctuationCapitalizationModel was successfully restored from C:\\Users\\Blob2\\.cache\\torch\\NeMo\\NeMo_1.0.0rc1\\Punctuation_Capitalization_with_BERT\\963746287f3f56c17e788b02881e7447\\Punctuation_Capitalization_with_BERT.nemo.\n"
     ]
    }
   ],
   "source": [
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rural-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method restore_from in module nemo.core.classes.modelPT:\n",
      "\n",
      "restore_from(restore_path: str, override_config_path: Union[omegaconf.omegaconf.OmegaConf, str, NoneType] = None, map_location: Union[torch.device, NoneType] = None, strict: bool = False, return_config: bool = False) method of abc.ABCMeta instance\n",
      "    Restores model instance (weights and configuration) from file.\n",
      "    \n",
      "    The methods tries to load it as EFF archive.\n",
      "    If EFF library is not present in the system, or the indicated file is not EFF archive,\n",
      "    the function defaults to the original .nemo restore method.\n",
      "    \n",
      "    Args:\n",
      "        restore_path: path to .nemo file from which model should be instantiated\n",
      "        override_config_path: path to a yaml config that will override the internal\n",
      "            config file or an OmegaConf / DictConfig object representing the model config.\n",
      "        map_location: Optional torch.device() to map the instantiated model to a device.\n",
      "            By default (None), it will select a GPU if available, falling back to CPU otherwise.\n",
      "        strict: Passed to load_state_dict.\n",
      "        return_config: If set to true, will return just the underlying config of the restored\n",
      "            model as an OmegaConf DictConfig object without instantiating the model.\n",
      "    \n",
      "        Example:\n",
      "            ```\n",
      "            model = nemo.collections.asr.models.EncDecCTCModel.restore_from('asr.nemo')\n",
      "            assert isinstance(model, nemo.collections.asr.models.EncDecCTCModel)\n",
      "            ```\n",
      "    \n",
      "    Returns:\n",
      "        An instance of type cls or its underlying config (if return_config is set).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nemo_asr.models.EncDecCTCModelBPE.restore_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ready-harvard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-06-09 13:06:05 modelPT:193] Using C:\\Users\\Blob2\\AppData\\Local\\Temp\\tmpq4uxptdj\\tokenizer.model instead of /tokenizers/nemo_asr_set/nemo_asr_set_1.4/no_appen/tokenizer_spe_unigram_v128/tokenizer.model.\n",
      "[NeMo W 2021-06-09 13:06:05 modelPT:193] Using C:\\Users\\Blob2\\AppData\\Local\\Temp\\tmpq4uxptdj\\vocab.txt instead of /tokenizers/nemo_asr_set/nemo_asr_set_1.4/no_appen/tokenizer_spe_unigram_v128/vocab.txt.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 2: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-09c313774463>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnemo_asr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEncDecCTCModelBPE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./speech/dependencies/stt_en_conformer_ctc_large.nemo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\nemo\\core\\classes\\modelPT.py\u001b[0m in \u001b[0;36mrestore_from\u001b[1;34m(cls, restore_path, override_config_path, map_location, strict, return_config)\u001b[0m\n\u001b[0;32m    507\u001b[0m                 \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m             )\n\u001b[0m\u001b[0;32m    510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\nemo\\core\\classes\\modelPT.py\u001b[0m in \u001b[0;36m_default_restore_from\u001b[1;34m(cls, restore_path, override_config_path, map_location, strict, return_config)\u001b[0m\n\u001b[0;32m    407\u001b[0m                     \u001b[0mconfig_yaml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_MODEL_CONFIG_YAML\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[1;31m# can be str path or OmegaConf / DictConfig object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                     \u001b[0mconfig_yaml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moverride_config_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_yaml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOmegaConf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDictConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\nemo\\core\\classes\\common.py\u001b[0m in \u001b[0;36mfrom_config_dict\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhydra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstantiate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;31m# Hydra 1.x API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[1;34m'_target_'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;31m# regular hydra-based instantiation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhydra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstantiate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\nemo\\collections\\asr\\models\\ctc_bpe_models.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, cfg, trainer)\u001b[0m\n\u001b[0;32m     61\u001b[0m         model = PretrainedModelInfo(\n\u001b[0;32m     62\u001b[0m             \u001b[0mpretrained_model_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"stt_en_citrinet_1024\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"For details about this model, please visit https://ngc.nvidia.com/catalog/models/nvidia:nemo:stt_en_citrinet_1024\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_citrinet_1024/versions/1.0.0rc1/files/stt_en_citrinet_1024.nemo\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\nemo\\collections\\asr\\parts\\mixins.py\u001b[0m in \u001b[0;36m_setup_tokenizer\u001b[1;34m(self, tokenizer_cfg)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 2: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "conformer = nemo_asr.models.EncDecCTCModelBPE.restore_from(\"./speech/dependencies/stt_en_conformer_ctc_large.nemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name='Punctuation_Capitalization_with_BERT').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "positive-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_FILENAME = './speech/transcribed_audio/test1.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "european-shopper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw recognized text: this video mis show what we need to do in order to have a two screen monitor set up running a ah vepad spow client right now i have just one stream going um we hid the reload here so i have my map on the left stream which is not the main screen that my spoke lides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind yere i open this really what i want to show is when i have my video player up and i clicked the mapt looks like it's not hiding now before i was hiding behind allright what's can weent\n"
     ]
    }
   ],
   "source": [
    "files = [AUDIO_FILENAME]\n",
    "raw_text = ''\n",
    "for fname, transcription in zip(files, quartznet.transcribe(paths2audio_files=files)):\n",
    "    raw_text = transcription\n",
    "    print(f'\\nRaw recognized text: {raw_text}')                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-format",
   "metadata": {},
   "source": [
    "## NeMo Timestamp test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "equipped-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax implementation in NumPy\n",
    "def softmax(logits):\n",
    "    e = np.exp(logits - np.max(logits))\n",
    "    return e / e.sum(axis=-1).reshape([logits.shape[0], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "enabling-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do inference once again but without decoder\n",
    "logits = quartznet.transcribe(files, logprobs=True)[0].cpu().numpy()\n",
    "probs = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "manual-hungarian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 20ms is duration of a timestep at output of the model\n",
    "time_stride = 0.02\n",
    "\n",
    "# get model's alphabet\n",
    "labels = list(quartznet.cfg.decoder.vocabulary) + ['blank']\n",
    "labels[0] = 'space'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "international-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get timestamps for space symbols\n",
    "spaces = []\n",
    "state = ''\n",
    "idx_state = 0\n",
    "\n",
    "if np.argmax(probs[0]) == 0:\n",
    "    state = 'space'\n",
    "\n",
    "for idx in range(1, probs.shape[0]):\n",
    "    current_char_idx = np.argmax(probs[idx])\n",
    "    if state == 'space' and current_char_idx != 0:\n",
    "        spaces.append([idx_state, idx-1])\n",
    "        state = ''\n",
    "    if state == '':\n",
    "        if current_char_idx == 0:\n",
    "            state = 'space'\n",
    "            idx_state = idx\n",
    "\n",
    "if state == 'space':\n",
    "    spaces.append([idx_state, len(pred)-1])\n",
    "    \n",
    "# calibration offset for timestamps: 180 ms\n",
    "offset = -0.18\n",
    "# split the transcript into words\n",
    "words = raw_text.replace('  ',' ').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "smooth-nurse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: this\n",
      "Start: 0\n",
      "End: 0.8\n",
      "\n",
      "\n",
      "Word: video\n",
      "Start: 0.8\n",
      "End: 1.17\n",
      "\n",
      "\n",
      "Word: mis\n",
      "Start: 1.17\n",
      "End: 1.41\n",
      "\n",
      "\n",
      "Word: show\n",
      "Start: 1.41\n",
      "End: 2.63\n",
      "\n",
      "\n",
      "Word: what\n",
      "Start: 2.63\n",
      "End: 3.12\n",
      "\n",
      "\n",
      "Word: we\n",
      "Start: 3.12\n",
      "End: 3.27\n",
      "\n",
      "\n",
      "Word: need\n",
      "Start: 3.27\n",
      "End: 3.46\n",
      "\n",
      "\n",
      "Word: to\n",
      "Start: 3.46\n",
      "End: 3.59\n",
      "\n",
      "\n",
      "Word: do\n",
      "Start: 3.59\n",
      "End: 4.05\n",
      "\n",
      "\n",
      "Word: in\n",
      "Start: 4.05\n",
      "End: 4.52\n",
      "\n",
      "\n",
      "Word: order\n",
      "Start: 4.52\n",
      "End: 4.85\n",
      "\n",
      "\n",
      "Word: to\n",
      "Start: 4.85\n",
      "End: 5.0\n",
      "\n",
      "\n",
      "Word: have\n",
      "Start: 5.0\n",
      "End: 5.22\n",
      "\n",
      "\n",
      "Word: a\n",
      "Start: 5.22\n",
      "End: 5.35\n",
      "\n",
      "\n",
      "Word: two\n",
      "Start: 5.35\n",
      "End: 5.6\n",
      "\n",
      "\n",
      "Word: screen\n",
      "Start: 5.6\n",
      "End: 5.96\n",
      "\n",
      "\n",
      "Word: monitor\n",
      "Start: 5.96\n",
      "End: 6.41\n",
      "\n",
      "\n",
      "Word: set\n",
      "Start: 6.41\n",
      "End: 6.64\n",
      "\n",
      "\n",
      "Word: up\n",
      "Start: 6.64\n",
      "End: 7.5\n",
      "\n",
      "\n",
      "Word: running\n",
      "Start: 7.5\n",
      "End: 8.19\n",
      "\n",
      "\n",
      "Word: a\n",
      "Start: 8.19\n",
      "End: 8.37\n",
      "\n",
      "\n",
      "Word: ah\n",
      "Start: 8.37\n",
      "End: 8.74\n",
      "\n",
      "\n",
      "Word: vepad\n",
      "Start: 8.74\n",
      "End: 9.46\n",
      "\n",
      "\n",
      "Word: spow\n",
      "Start: 9.46\n",
      "End: 9.81\n",
      "\n",
      "\n",
      "Word: client\n",
      "Start: 9.81\n",
      "End: 11.12\n",
      "\n",
      "\n",
      "Word: right\n",
      "Start: 11.12\n",
      "End: 11.43\n",
      "\n",
      "\n",
      "Word: now\n",
      "Start: 11.43\n",
      "End: 11.62\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 11.62\n",
      "End: 11.77\n",
      "\n",
      "\n",
      "Word: have\n",
      "Start: 11.77\n",
      "End: 12.61\n",
      "\n",
      "\n",
      "Word: just\n",
      "Start: 12.61\n",
      "End: 13.41\n",
      "\n",
      "\n",
      "Word: one\n",
      "Start: 13.41\n",
      "End: 13.69\n",
      "\n",
      "\n",
      "Word: stream\n",
      "Start: 13.69\n",
      "End: 14.08\n",
      "\n",
      "\n",
      "Word: going\n",
      "Start: 14.08\n",
      "End: 16.4\n",
      "\n",
      "\n",
      "Word: um\n",
      "Start: 16.4\n",
      "End: 16.81\n",
      "\n",
      "\n",
      "Word: we\n",
      "Start: 16.81\n",
      "End: 17.24\n",
      "\n",
      "\n",
      "Word: hid\n",
      "Start: 17.24\n",
      "End: 17.41\n",
      "\n",
      "\n",
      "Word: the\n",
      "Start: 17.41\n",
      "End: 17.53\n",
      "\n",
      "\n",
      "Word: reload\n",
      "Start: 17.53\n",
      "End: 17.97\n",
      "\n",
      "\n",
      "Word: here\n",
      "Start: 17.97\n",
      "End: 19.73\n",
      "\n",
      "\n",
      "Word: so\n",
      "Start: 19.73\n",
      "End: 20.02\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 20.02\n",
      "End: 20.13\n",
      "\n",
      "\n",
      "Word: have\n",
      "Start: 20.13\n",
      "End: 20.26\n",
      "\n",
      "\n",
      "Word: my\n",
      "Start: 20.26\n",
      "End: 20.38\n",
      "\n",
      "\n",
      "Word: map\n",
      "Start: 20.38\n",
      "End: 20.64\n",
      "\n",
      "\n",
      "Word: on\n",
      "Start: 20.64\n",
      "End: 20.74\n",
      "\n",
      "\n",
      "Word: the\n",
      "Start: 20.74\n",
      "End: 20.86\n",
      "\n",
      "\n",
      "Word: left\n",
      "Start: 20.86\n",
      "End: 21.09\n",
      "\n",
      "\n",
      "Word: stream\n",
      "Start: 21.09\n",
      "End: 21.42\n",
      "\n",
      "\n",
      "Word: which\n",
      "Start: 21.42\n",
      "End: 21.63\n",
      "\n",
      "\n",
      "Word: is\n",
      "Start: 21.63\n",
      "End: 21.81\n",
      "\n",
      "\n",
      "Word: not\n",
      "Start: 21.81\n",
      "End: 22.03\n",
      "\n",
      "\n",
      "Word: the\n",
      "Start: 22.03\n",
      "End: 22.32\n",
      "\n",
      "\n",
      "Word: main\n",
      "Start: 22.32\n",
      "End: 22.76\n",
      "\n",
      "\n",
      "Word: screen\n",
      "Start: 22.76\n",
      "End: 23.1\n",
      "\n",
      "\n",
      "Word: that\n",
      "Start: 23.1\n",
      "End: 23.27\n",
      "\n",
      "\n",
      "Word: my\n",
      "Start: 23.27\n",
      "End: 23.54\n",
      "\n",
      "\n",
      "Word: spoke\n",
      "Start: 23.54\n",
      "End: 24.06\n",
      "\n",
      "\n",
      "Word: lides\n",
      "Start: 24.06\n",
      "End: 24.46\n",
      "\n",
      "\n",
      "Word: running\n",
      "Start: 24.46\n",
      "End: 24.73\n",
      "\n",
      "\n",
      "Word: on\n",
      "Start: 24.73\n",
      "End: 27.37\n",
      "\n",
      "\n",
      "Word: so\n",
      "Start: 27.37\n",
      "End: 27.69\n",
      "\n",
      "\n",
      "Word: mi\n",
      "Start: 27.69\n",
      "End: 27.88\n",
      "\n",
      "\n",
      "Word: see\n",
      "Start: 27.88\n",
      "End: 28.04\n",
      "\n",
      "\n",
      "Word: if\n",
      "Start: 28.04\n",
      "End: 28.14\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 28.14\n",
      "End: 28.23\n",
      "\n",
      "\n",
      "Word: can\n",
      "Start: 28.23\n",
      "End: 28.37\n",
      "\n",
      "\n",
      "Word: drag\n",
      "Start: 28.37\n",
      "End: 28.63\n",
      "\n",
      "\n",
      "Word: it\n",
      "Start: 28.63\n",
      "End: 28.74\n",
      "\n",
      "\n",
      "Word: over\n",
      "Start: 28.74\n",
      "End: 29.79\n",
      "\n",
      "\n",
      "Word: so\n",
      "Start: 29.79\n",
      "End: 30.22\n",
      "\n",
      "\n",
      "Word: it\n",
      "Start: 30.22\n",
      "End: 30.33\n",
      "\n",
      "\n",
      "Word: looks\n",
      "Start: 30.33\n",
      "End: 30.51\n",
      "\n",
      "\n",
      "Word: like\n",
      "Start: 30.51\n",
      "End: 30.64\n",
      "\n",
      "\n",
      "Word: when\n",
      "Start: 30.64\n",
      "End: 30.79\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 30.79\n",
      "End: 30.9\n",
      "\n",
      "\n",
      "Word: drag\n",
      "Start: 30.9\n",
      "End: 31.14\n",
      "\n",
      "\n",
      "Word: it\n",
      "Start: 31.14\n",
      "End: 31.27\n",
      "\n",
      "\n",
      "Word: to\n",
      "Start: 31.27\n",
      "End: 31.4\n",
      "\n",
      "\n",
      "Word: the\n",
      "Start: 31.4\n",
      "End: 31.54\n",
      "\n",
      "\n",
      "Word: left\n",
      "Start: 31.54\n",
      "End: 32.47\n",
      "\n",
      "\n",
      "Word: it's\n",
      "Start: 32.47\n",
      "End: 32.65\n",
      "\n",
      "\n",
      "Word: going\n",
      "Start: 32.65\n",
      "End: 32.93\n",
      "\n",
      "\n",
      "Word: behind\n",
      "Start: 32.93\n",
      "End: 33.27\n",
      "\n",
      "\n",
      "Word: the\n",
      "Start: 33.27\n",
      "End: 33.4\n",
      "\n",
      "\n",
      "Word: map\n",
      "Start: 33.4\n",
      "End: 37.0\n",
      "\n",
      "\n",
      "Word: she\n",
      "Start: 37.0\n",
      "End: 37.18\n",
      "\n",
      "\n",
      "Word: is\n",
      "Start: 37.18\n",
      "End: 37.35\n",
      "\n",
      "\n",
      "Word: behind\n",
      "Start: 37.35\n",
      "End: 37.81\n",
      "\n",
      "\n",
      "Word: yere\n",
      "Start: 37.81\n",
      "End: 38.87\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 38.87\n",
      "End: 39.07\n",
      "\n",
      "\n",
      "Word: open\n",
      "Start: 39.07\n",
      "End: 39.38\n",
      "\n",
      "\n",
      "Word: this\n",
      "Start: 39.38\n",
      "End: 46.35\n",
      "\n",
      "\n",
      "Word: really\n",
      "Start: 46.35\n",
      "End: 46.7\n",
      "\n",
      "\n",
      "Word: what\n",
      "Start: 46.7\n",
      "End: 46.88\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 46.88\n",
      "End: 47.0\n",
      "\n",
      "\n",
      "Word: want\n",
      "Start: 47.0\n",
      "End: 47.17\n",
      "\n",
      "\n",
      "Word: to\n",
      "Start: 47.17\n",
      "End: 47.29\n",
      "\n",
      "\n",
      "Word: show\n",
      "Start: 47.29\n",
      "End: 47.55\n",
      "\n",
      "\n",
      "Word: is\n",
      "Start: 47.55\n",
      "End: 51.29\n",
      "\n",
      "\n",
      "Word: when\n",
      "Start: 51.29\n",
      "End: 51.48\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 51.48\n",
      "End: 51.6\n",
      "\n",
      "\n",
      "Word: have\n",
      "Start: 51.6\n",
      "End: 51.79\n",
      "\n",
      "\n",
      "Word: my\n",
      "Start: 51.79\n",
      "End: 51.99\n",
      "\n",
      "\n",
      "Word: video\n",
      "Start: 51.99\n",
      "End: 52.4\n",
      "\n",
      "\n",
      "Word: player\n",
      "Start: 52.4\n",
      "End: 52.69\n",
      "\n",
      "\n",
      "Word: up\n",
      "Start: 52.69\n",
      "End: 54.76\n",
      "\n",
      "\n",
      "Word: and\n",
      "Start: 54.76\n",
      "End: 54.97\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 54.97\n",
      "End: 55.08\n",
      "\n",
      "\n",
      "Word: clicked\n",
      "Start: 55.08\n",
      "End: 55.35\n",
      "\n",
      "\n",
      "Word: the\n",
      "Start: 55.35\n",
      "End: 55.47\n",
      "\n",
      "\n",
      "Word: mapt\n",
      "Start: 55.47\n",
      "End: 61.41\n",
      "\n",
      "\n",
      "Word: looks\n",
      "Start: 61.41\n",
      "End: 61.68\n",
      "\n",
      "\n",
      "Word: like\n",
      "Start: 61.68\n",
      "End: 61.83\n",
      "\n",
      "\n",
      "Word: it's\n",
      "Start: 61.83\n",
      "End: 62.02\n",
      "\n",
      "\n",
      "Word: not\n",
      "Start: 62.02\n",
      "End: 62.23\n",
      "\n",
      "\n",
      "Word: hiding\n",
      "Start: 62.23\n",
      "End: 62.62\n",
      "\n",
      "\n",
      "Word: now\n",
      "Start: 62.62\n",
      "End: 63.88\n",
      "\n",
      "\n",
      "Word: before\n",
      "Start: 63.88\n",
      "End: 64.24\n",
      "\n",
      "\n",
      "Word: i\n",
      "Start: 64.24\n",
      "End: 64.34\n",
      "\n",
      "\n",
      "Word: was\n",
      "Start: 64.34\n",
      "End: 64.48\n",
      "\n",
      "\n",
      "Word: hiding\n",
      "Start: 64.48\n",
      "End: 64.81\n",
      "\n",
      "\n",
      "Word: behind\n",
      "Start: 64.81\n",
      "End: 67.92\n",
      "\n",
      "\n",
      "Word: allright\n",
      "Start: 67.92\n",
      "End: 68.39\n",
      "\n",
      "\n",
      "Word: what's\n",
      "Start: 68.39\n",
      "End: 68.8\n",
      "\n",
      "\n",
      "Word: can\n",
      "Start: 68.8\n",
      "End: 68.99\n",
      "\n",
      "\n",
      "Word: weent\n",
      "Start: 68.99\n",
      "End: 68.99\n"
     ]
    }
   ],
   "source": [
    "# cut words\n",
    "pos_prev = 0\n",
    "try:\n",
    "    for i, spot in enumerate(spaces):\n",
    "        pos_end = offset + (spot[0]+spot[1])/2*time_stride\n",
    "        print('Word:', words[i])\n",
    "        print('Start:', round(pos_prev, 2))\n",
    "        print('End:', round(pos_end, 2))\n",
    "\n",
    "        pos_prev = pos_end\n",
    "        print('\\n')\n",
    "\n",
    "    print('Word:', words[i+1])\n",
    "    print('Start:', round(pos_prev, 2))\n",
    "    pos_end = offset + (spot[0]+spot[1])/2*time_stride\n",
    "    print('End:', round(pos_end, 2))\n",
    "except IndexError as error:\n",
    "    print(error)\n",
    "    print('Continuing...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "employed-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all in one function and put into dict\n",
    "def nemo_timestamps(audio_files, model, raw_text):\n",
    "    #inference without decoder\n",
    "    logits = model.transcribe(audio_files, logprobs=True)[0].cpu().numpy()\n",
    "    probs = softmax(logits)\n",
    "\n",
    "    # 20ms is duration of a timestep at output of the model\n",
    "    time_stride = 0.02\n",
    "\n",
    "    # get model's alphabet\n",
    "    labels = list(model.cfg.decoder.vocabulary) + ['blank']\n",
    "    labels[0] = 'space'\n",
    "\n",
    "    # get timestamps for space symbols\n",
    "    spaces = []\n",
    "    state = ''\n",
    "    idx_state = 0\n",
    "\n",
    "    if np.argmax(probs[0]) == 0:\n",
    "        state = 'space'\n",
    "\n",
    "    for idx in range(1, probs.shape[0]):\n",
    "        current_char_idx = np.argmax(probs[idx])\n",
    "        if state == 'space' and current_char_idx != 0:\n",
    "            spaces.append([idx_state, idx - 1])\n",
    "            state = ''\n",
    "        if state == '':\n",
    "            if current_char_idx == 0:\n",
    "                state = 'space'\n",
    "                idx_state = idx\n",
    "\n",
    "    if state == 'space':\n",
    "        spaces.append([idx_state, len(pred) - 1])\n",
    "\n",
    "    # calibration offset for timestamps: 180 ms\n",
    "    offset = -0.18\n",
    "\n",
    "    # split the transcript into words\n",
    "    words = raw_text.replace('  ', ' ').split()\n",
    "\n",
    "    #cut words with start and end times and put into dictionary\n",
    "    pos_prev = 0\n",
    "    with_times = []\n",
    "    try:\n",
    "        for i, spot in enumerate(spaces):\n",
    "            pos_end = offset + (spot[0] + spot[1]) / 2 * time_stride\n",
    "\n",
    "            individual = {}\n",
    "            individual['word'] = words[i]\n",
    "            individual['start_time'] = round(pos_prev, 2)\n",
    "            individual['end_time'] = round(pos_end, 2)\n",
    "            with_times.append(individual)\n",
    "\n",
    "            pos_prev = pos_end\n",
    "\n",
    "        individual['word'] = words[i + 1]\n",
    "        individual['start_time'] = round(pos_prev, 2)\n",
    "        pos_end = offset + (spot[0] + spot[1]) / 2 * time_stride\n",
    "        individual['end_time'] = round(pos_end, 2)\n",
    "        with_times.append(individual)\n",
    "\n",
    "    except IndexError as error:\n",
    "        print(error)\n",
    "        print('Continuing...')\n",
    "\n",
    "    return with_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecological-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_times = nemo_timestamps(files, quartznet, raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "stuck-ability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'this', 'start_time': 0, 'end_time': 0.8},\n",
       " {'word': 'video', 'start_time': 0.8, 'end_time': 1.17},\n",
       " {'word': 'mis', 'start_time': 1.17, 'end_time': 1.41},\n",
       " {'word': 'show', 'start_time': 1.41, 'end_time': 2.63},\n",
       " {'word': 'what', 'start_time': 2.63, 'end_time': 3.12},\n",
       " {'word': 'we', 'start_time': 3.12, 'end_time': 3.27},\n",
       " {'word': 'need', 'start_time': 3.27, 'end_time': 3.46},\n",
       " {'word': 'to', 'start_time': 3.46, 'end_time': 3.59},\n",
       " {'word': 'do', 'start_time': 3.59, 'end_time': 4.05},\n",
       " {'word': 'in', 'start_time': 4.05, 'end_time': 4.52},\n",
       " {'word': 'order', 'start_time': 4.52, 'end_time': 4.85},\n",
       " {'word': 'to', 'start_time': 4.85, 'end_time': 5.0},\n",
       " {'word': 'have', 'start_time': 5.0, 'end_time': 5.22},\n",
       " {'word': 'a', 'start_time': 5.22, 'end_time': 5.35},\n",
       " {'word': 'two', 'start_time': 5.35, 'end_time': 5.6},\n",
       " {'word': 'screen', 'start_time': 5.6, 'end_time': 5.96},\n",
       " {'word': 'monitor', 'start_time': 5.96, 'end_time': 6.41},\n",
       " {'word': 'set', 'start_time': 6.41, 'end_time': 6.64},\n",
       " {'word': 'up', 'start_time': 6.64, 'end_time': 7.5},\n",
       " {'word': 'running', 'start_time': 7.5, 'end_time': 8.19},\n",
       " {'word': 'a', 'start_time': 8.19, 'end_time': 8.37},\n",
       " {'word': 'ah', 'start_time': 8.37, 'end_time': 8.74},\n",
       " {'word': 'vepad', 'start_time': 8.74, 'end_time': 9.46},\n",
       " {'word': 'spow', 'start_time': 9.46, 'end_time': 9.81},\n",
       " {'word': 'client', 'start_time': 9.81, 'end_time': 11.12},\n",
       " {'word': 'right', 'start_time': 11.12, 'end_time': 11.43},\n",
       " {'word': 'now', 'start_time': 11.43, 'end_time': 11.62},\n",
       " {'word': 'i', 'start_time': 11.62, 'end_time': 11.77},\n",
       " {'word': 'have', 'start_time': 11.77, 'end_time': 12.61},\n",
       " {'word': 'just', 'start_time': 12.61, 'end_time': 13.41},\n",
       " {'word': 'one', 'start_time': 13.41, 'end_time': 13.69},\n",
       " {'word': 'stream', 'start_time': 13.69, 'end_time': 14.08},\n",
       " {'word': 'going', 'start_time': 14.08, 'end_time': 16.4},\n",
       " {'word': 'um', 'start_time': 16.4, 'end_time': 16.81},\n",
       " {'word': 'we', 'start_time': 16.81, 'end_time': 17.24},\n",
       " {'word': 'hid', 'start_time': 17.24, 'end_time': 17.41},\n",
       " {'word': 'the', 'start_time': 17.41, 'end_time': 17.53},\n",
       " {'word': 'reload', 'start_time': 17.53, 'end_time': 17.97},\n",
       " {'word': 'here', 'start_time': 17.97, 'end_time': 19.73},\n",
       " {'word': 'so', 'start_time': 19.73, 'end_time': 20.02},\n",
       " {'word': 'i', 'start_time': 20.02, 'end_time': 20.13},\n",
       " {'word': 'have', 'start_time': 20.13, 'end_time': 20.26},\n",
       " {'word': 'my', 'start_time': 20.26, 'end_time': 20.38},\n",
       " {'word': 'map', 'start_time': 20.38, 'end_time': 20.64},\n",
       " {'word': 'on', 'start_time': 20.64, 'end_time': 20.74},\n",
       " {'word': 'the', 'start_time': 20.74, 'end_time': 20.86},\n",
       " {'word': 'left', 'start_time': 20.86, 'end_time': 21.09},\n",
       " {'word': 'stream', 'start_time': 21.09, 'end_time': 21.42},\n",
       " {'word': 'which', 'start_time': 21.42, 'end_time': 21.63},\n",
       " {'word': 'is', 'start_time': 21.63, 'end_time': 21.81},\n",
       " {'word': 'not', 'start_time': 21.81, 'end_time': 22.03},\n",
       " {'word': 'the', 'start_time': 22.03, 'end_time': 22.32},\n",
       " {'word': 'main', 'start_time': 22.32, 'end_time': 22.76},\n",
       " {'word': 'screen', 'start_time': 22.76, 'end_time': 23.1},\n",
       " {'word': 'that', 'start_time': 23.1, 'end_time': 23.27},\n",
       " {'word': 'my', 'start_time': 23.27, 'end_time': 23.54},\n",
       " {'word': 'spoke', 'start_time': 23.54, 'end_time': 24.06},\n",
       " {'word': 'lides', 'start_time': 24.06, 'end_time': 24.46},\n",
       " {'word': 'running', 'start_time': 24.46, 'end_time': 24.73},\n",
       " {'word': 'on', 'start_time': 24.73, 'end_time': 27.37},\n",
       " {'word': 'so', 'start_time': 27.37, 'end_time': 27.69},\n",
       " {'word': 'mi', 'start_time': 27.69, 'end_time': 27.88},\n",
       " {'word': 'see', 'start_time': 27.88, 'end_time': 28.04},\n",
       " {'word': 'if', 'start_time': 28.04, 'end_time': 28.14},\n",
       " {'word': 'i', 'start_time': 28.14, 'end_time': 28.23},\n",
       " {'word': 'can', 'start_time': 28.23, 'end_time': 28.37},\n",
       " {'word': 'drag', 'start_time': 28.37, 'end_time': 28.63},\n",
       " {'word': 'it', 'start_time': 28.63, 'end_time': 28.74},\n",
       " {'word': 'over', 'start_time': 28.74, 'end_time': 29.79},\n",
       " {'word': 'so', 'start_time': 29.79, 'end_time': 30.22},\n",
       " {'word': 'it', 'start_time': 30.22, 'end_time': 30.33},\n",
       " {'word': 'looks', 'start_time': 30.33, 'end_time': 30.51},\n",
       " {'word': 'like', 'start_time': 30.51, 'end_time': 30.64},\n",
       " {'word': 'when', 'start_time': 30.64, 'end_time': 30.79},\n",
       " {'word': 'i', 'start_time': 30.79, 'end_time': 30.9},\n",
       " {'word': 'drag', 'start_time': 30.9, 'end_time': 31.14},\n",
       " {'word': 'it', 'start_time': 31.14, 'end_time': 31.27},\n",
       " {'word': 'to', 'start_time': 31.27, 'end_time': 31.4},\n",
       " {'word': 'the', 'start_time': 31.4, 'end_time': 31.54},\n",
       " {'word': 'left', 'start_time': 31.54, 'end_time': 32.47},\n",
       " {'word': \"it's\", 'start_time': 32.47, 'end_time': 32.65},\n",
       " {'word': 'going', 'start_time': 32.65, 'end_time': 32.93},\n",
       " {'word': 'behind', 'start_time': 32.93, 'end_time': 33.27},\n",
       " {'word': 'the', 'start_time': 33.27, 'end_time': 33.4},\n",
       " {'word': 'map', 'start_time': 33.4, 'end_time': 37.0},\n",
       " {'word': 'she', 'start_time': 37.0, 'end_time': 37.18},\n",
       " {'word': 'is', 'start_time': 37.18, 'end_time': 37.35},\n",
       " {'word': 'behind', 'start_time': 37.35, 'end_time': 37.81},\n",
       " {'word': 'yere', 'start_time': 37.81, 'end_time': 38.87},\n",
       " {'word': 'i', 'start_time': 38.87, 'end_time': 39.07},\n",
       " {'word': 'open', 'start_time': 39.07, 'end_time': 39.38},\n",
       " {'word': 'this', 'start_time': 39.38, 'end_time': 46.35},\n",
       " {'word': 'really', 'start_time': 46.35, 'end_time': 46.7},\n",
       " {'word': 'what', 'start_time': 46.7, 'end_time': 46.88},\n",
       " {'word': 'i', 'start_time': 46.88, 'end_time': 47.0},\n",
       " {'word': 'want', 'start_time': 47.0, 'end_time': 47.17},\n",
       " {'word': 'to', 'start_time': 47.17, 'end_time': 47.29},\n",
       " {'word': 'show', 'start_time': 47.29, 'end_time': 47.55},\n",
       " {'word': 'is', 'start_time': 47.55, 'end_time': 51.29},\n",
       " {'word': 'when', 'start_time': 51.29, 'end_time': 51.48},\n",
       " {'word': 'i', 'start_time': 51.48, 'end_time': 51.6},\n",
       " {'word': 'have', 'start_time': 51.6, 'end_time': 51.79},\n",
       " {'word': 'my', 'start_time': 51.79, 'end_time': 51.99},\n",
       " {'word': 'video', 'start_time': 51.99, 'end_time': 52.4},\n",
       " {'word': 'player', 'start_time': 52.4, 'end_time': 52.69},\n",
       " {'word': 'up', 'start_time': 52.69, 'end_time': 54.76},\n",
       " {'word': 'and', 'start_time': 54.76, 'end_time': 54.97},\n",
       " {'word': 'i', 'start_time': 54.97, 'end_time': 55.08},\n",
       " {'word': 'clicked', 'start_time': 55.08, 'end_time': 55.35},\n",
       " {'word': 'the', 'start_time': 55.35, 'end_time': 55.47},\n",
       " {'word': 'mapt', 'start_time': 55.47, 'end_time': 61.41},\n",
       " {'word': 'looks', 'start_time': 61.41, 'end_time': 61.68},\n",
       " {'word': 'like', 'start_time': 61.68, 'end_time': 61.83},\n",
       " {'word': \"it's\", 'start_time': 61.83, 'end_time': 62.02},\n",
       " {'word': 'not', 'start_time': 62.02, 'end_time': 62.23},\n",
       " {'word': 'hiding', 'start_time': 62.23, 'end_time': 62.62},\n",
       " {'word': 'now', 'start_time': 62.62, 'end_time': 63.88},\n",
       " {'word': 'before', 'start_time': 63.88, 'end_time': 64.24},\n",
       " {'word': 'i', 'start_time': 64.24, 'end_time': 64.34},\n",
       " {'word': 'was', 'start_time': 64.34, 'end_time': 64.48},\n",
       " {'word': 'hiding', 'start_time': 64.48, 'end_time': 64.81},\n",
       " {'word': 'behind', 'start_time': 64.81, 'end_time': 67.92},\n",
       " {'word': 'allright', 'start_time': 67.92, 'end_time': 68.39},\n",
       " {'word': \"what's\", 'start_time': 68.39, 'end_time': 68.8},\n",
       " {'word': 'weent', 'start_time': 68.99, 'end_time': 68.99},\n",
       " {'word': 'weent', 'start_time': 68.99, 'end_time': 68.99}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-treasure",
   "metadata": {},
   "source": [
    "## Acronym pattern detection and Common ASR fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "framed-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stutters(input_text, time_format=False):\n",
    "    if not time_format:\n",
    "        output_text = re.sub(r\"\\sum\\s\",\" \", input_text)\n",
    "        output_text = re.sub(r\"\\sah\\s\",\" \", output_text)\n",
    "        output_text = re.sub(r\"\\suh\\s\",\" \", output_text)\n",
    "        output_text = re.sub(r\"\\seh\\s\",\" \", output_text)\n",
    "        return output_text\n",
    "    if time_format:\n",
    "        for word_dict in input_text:\n",
    "            if word_dict['word']=='um' or word_dict['word']=='ah' or word_dict['word']=='uh' or word_dict['word']=='eh':\n",
    "                input_text.remove(word_dict)\n",
    "        return input_text\n",
    "    \n",
    "def common_corrections(input_text, time_format=False):\n",
    "    mistakes = ['censors', 'classifieers', 'smartfo', '  ', 'medison', 'alln', 'year', 'yere', 'veilance', 'permaners', 'thes s', 'allright', 'mapt']\n",
    "    replacements = ['sensors', 'classifiers', 'smartphone', ' ', 'medicine', 'all-in','here','here','surveillance', 'perimeter', 'this is', 'alright', 'map']\n",
    "    \n",
    "    output_text = input_text\n",
    "    \n",
    "    if not time_format:\n",
    "        mini_count =0\n",
    "        for word in mistakes:\n",
    "            output_text = re.sub(mistakes[mini_count],replacements[mini_count], output_text)\n",
    "            mini_count+=1\n",
    "        return output_text\n",
    "    \n",
    "    if time_format:\n",
    "        for word_dict in input_text:\n",
    "            if word_dict['word'] in mistakes:\n",
    "                word_dict['word'] = replacements[mistakes.index(word_dict['word'])]\n",
    "        return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "interstate-prisoner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this video mis show what we need to do in order to have a two screen monitor set up running a vepad spow client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke lides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it's not hiding now before i was hiding behind alright what's can weent\n"
     ]
    }
   ],
   "source": [
    "common_text = remove_stutters(raw_text)\n",
    "common_text = common_corrections(common_text)\n",
    "print(common_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sudden-blogger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'this', 'start_time': 0, 'end_time': 0.8},\n",
       " {'word': 'video', 'start_time': 0.8, 'end_time': 1.17},\n",
       " {'word': 'mis', 'start_time': 1.17, 'end_time': 1.41},\n",
       " {'word': 'show', 'start_time': 1.41, 'end_time': 2.63},\n",
       " {'word': 'what', 'start_time': 2.63, 'end_time': 3.12},\n",
       " {'word': 'we', 'start_time': 3.12, 'end_time': 3.27},\n",
       " {'word': 'need', 'start_time': 3.27, 'end_time': 3.46},\n",
       " {'word': 'to', 'start_time': 3.46, 'end_time': 3.59},\n",
       " {'word': 'do', 'start_time': 3.59, 'end_time': 4.05},\n",
       " {'word': 'in', 'start_time': 4.05, 'end_time': 4.52},\n",
       " {'word': 'order', 'start_time': 4.52, 'end_time': 4.85},\n",
       " {'word': 'to', 'start_time': 4.85, 'end_time': 5.0},\n",
       " {'word': 'have', 'start_time': 5.0, 'end_time': 5.22},\n",
       " {'word': 'a', 'start_time': 5.22, 'end_time': 5.35},\n",
       " {'word': 'two', 'start_time': 5.35, 'end_time': 5.6},\n",
       " {'word': 'screen', 'start_time': 5.6, 'end_time': 5.96},\n",
       " {'word': 'monitor', 'start_time': 5.96, 'end_time': 6.41},\n",
       " {'word': 'set', 'start_time': 6.41, 'end_time': 6.64},\n",
       " {'word': 'up', 'start_time': 6.64, 'end_time': 7.5},\n",
       " {'word': 'running', 'start_time': 7.5, 'end_time': 8.19},\n",
       " {'word': 'a', 'start_time': 8.19, 'end_time': 8.37},\n",
       " {'word': 'vepad', 'start_time': 8.74, 'end_time': 9.46},\n",
       " {'word': 'spow', 'start_time': 9.46, 'end_time': 9.81},\n",
       " {'word': 'client', 'start_time': 9.81, 'end_time': 11.12},\n",
       " {'word': 'right', 'start_time': 11.12, 'end_time': 11.43},\n",
       " {'word': 'now', 'start_time': 11.43, 'end_time': 11.62},\n",
       " {'word': 'i', 'start_time': 11.62, 'end_time': 11.77},\n",
       " {'word': 'have', 'start_time': 11.77, 'end_time': 12.61},\n",
       " {'word': 'just', 'start_time': 12.61, 'end_time': 13.41},\n",
       " {'word': 'one', 'start_time': 13.41, 'end_time': 13.69},\n",
       " {'word': 'stream', 'start_time': 13.69, 'end_time': 14.08},\n",
       " {'word': 'going', 'start_time': 14.08, 'end_time': 16.4},\n",
       " {'word': 'we', 'start_time': 16.81, 'end_time': 17.24},\n",
       " {'word': 'hid', 'start_time': 17.24, 'end_time': 17.41},\n",
       " {'word': 'the', 'start_time': 17.41, 'end_time': 17.53},\n",
       " {'word': 'reload', 'start_time': 17.53, 'end_time': 17.97},\n",
       " {'word': 'here', 'start_time': 17.97, 'end_time': 19.73},\n",
       " {'word': 'so', 'start_time': 19.73, 'end_time': 20.02},\n",
       " {'word': 'i', 'start_time': 20.02, 'end_time': 20.13},\n",
       " {'word': 'have', 'start_time': 20.13, 'end_time': 20.26},\n",
       " {'word': 'my', 'start_time': 20.26, 'end_time': 20.38},\n",
       " {'word': 'map', 'start_time': 20.38, 'end_time': 20.64},\n",
       " {'word': 'on', 'start_time': 20.64, 'end_time': 20.74},\n",
       " {'word': 'the', 'start_time': 20.74, 'end_time': 20.86},\n",
       " {'word': 'left', 'start_time': 20.86, 'end_time': 21.09},\n",
       " {'word': 'stream', 'start_time': 21.09, 'end_time': 21.42},\n",
       " {'word': 'which', 'start_time': 21.42, 'end_time': 21.63},\n",
       " {'word': 'is', 'start_time': 21.63, 'end_time': 21.81},\n",
       " {'word': 'not', 'start_time': 21.81, 'end_time': 22.03},\n",
       " {'word': 'the', 'start_time': 22.03, 'end_time': 22.32},\n",
       " {'word': 'main', 'start_time': 22.32, 'end_time': 22.76},\n",
       " {'word': 'screen', 'start_time': 22.76, 'end_time': 23.1},\n",
       " {'word': 'that', 'start_time': 23.1, 'end_time': 23.27},\n",
       " {'word': 'my', 'start_time': 23.27, 'end_time': 23.54},\n",
       " {'word': 'spoke', 'start_time': 23.54, 'end_time': 24.06},\n",
       " {'word': 'lides', 'start_time': 24.06, 'end_time': 24.46},\n",
       " {'word': 'running', 'start_time': 24.46, 'end_time': 24.73},\n",
       " {'word': 'on', 'start_time': 24.73, 'end_time': 27.37},\n",
       " {'word': 'so', 'start_time': 27.37, 'end_time': 27.69},\n",
       " {'word': 'mi', 'start_time': 27.69, 'end_time': 27.88},\n",
       " {'word': 'see', 'start_time': 27.88, 'end_time': 28.04},\n",
       " {'word': 'if', 'start_time': 28.04, 'end_time': 28.14},\n",
       " {'word': 'i', 'start_time': 28.14, 'end_time': 28.23},\n",
       " {'word': 'can', 'start_time': 28.23, 'end_time': 28.37},\n",
       " {'word': 'drag', 'start_time': 28.37, 'end_time': 28.63},\n",
       " {'word': 'it', 'start_time': 28.63, 'end_time': 28.74},\n",
       " {'word': 'over', 'start_time': 28.74, 'end_time': 29.79},\n",
       " {'word': 'so', 'start_time': 29.79, 'end_time': 30.22},\n",
       " {'word': 'it', 'start_time': 30.22, 'end_time': 30.33},\n",
       " {'word': 'looks', 'start_time': 30.33, 'end_time': 30.51},\n",
       " {'word': 'like', 'start_time': 30.51, 'end_time': 30.64},\n",
       " {'word': 'when', 'start_time': 30.64, 'end_time': 30.79},\n",
       " {'word': 'i', 'start_time': 30.79, 'end_time': 30.9},\n",
       " {'word': 'drag', 'start_time': 30.9, 'end_time': 31.14},\n",
       " {'word': 'it', 'start_time': 31.14, 'end_time': 31.27},\n",
       " {'word': 'to', 'start_time': 31.27, 'end_time': 31.4},\n",
       " {'word': 'the', 'start_time': 31.4, 'end_time': 31.54},\n",
       " {'word': 'left', 'start_time': 31.54, 'end_time': 32.47},\n",
       " {'word': \"it's\", 'start_time': 32.47, 'end_time': 32.65},\n",
       " {'word': 'going', 'start_time': 32.65, 'end_time': 32.93},\n",
       " {'word': 'behind', 'start_time': 32.93, 'end_time': 33.27},\n",
       " {'word': 'the', 'start_time': 33.27, 'end_time': 33.4},\n",
       " {'word': 'map', 'start_time': 33.4, 'end_time': 37.0},\n",
       " {'word': 'she', 'start_time': 37.0, 'end_time': 37.18},\n",
       " {'word': 'is', 'start_time': 37.18, 'end_time': 37.35},\n",
       " {'word': 'behind', 'start_time': 37.35, 'end_time': 37.81},\n",
       " {'word': 'here', 'start_time': 37.81, 'end_time': 38.87},\n",
       " {'word': 'i', 'start_time': 38.87, 'end_time': 39.07},\n",
       " {'word': 'open', 'start_time': 39.07, 'end_time': 39.38},\n",
       " {'word': 'this', 'start_time': 39.38, 'end_time': 46.35},\n",
       " {'word': 'really', 'start_time': 46.35, 'end_time': 46.7},\n",
       " {'word': 'what', 'start_time': 46.7, 'end_time': 46.88},\n",
       " {'word': 'i', 'start_time': 46.88, 'end_time': 47.0},\n",
       " {'word': 'want', 'start_time': 47.0, 'end_time': 47.17},\n",
       " {'word': 'to', 'start_time': 47.17, 'end_time': 47.29},\n",
       " {'word': 'show', 'start_time': 47.29, 'end_time': 47.55},\n",
       " {'word': 'is', 'start_time': 47.55, 'end_time': 51.29},\n",
       " {'word': 'when', 'start_time': 51.29, 'end_time': 51.48},\n",
       " {'word': 'i', 'start_time': 51.48, 'end_time': 51.6},\n",
       " {'word': 'have', 'start_time': 51.6, 'end_time': 51.79},\n",
       " {'word': 'my', 'start_time': 51.79, 'end_time': 51.99},\n",
       " {'word': 'video', 'start_time': 51.99, 'end_time': 52.4},\n",
       " {'word': 'player', 'start_time': 52.4, 'end_time': 52.69},\n",
       " {'word': 'up', 'start_time': 52.69, 'end_time': 54.76},\n",
       " {'word': 'and', 'start_time': 54.76, 'end_time': 54.97},\n",
       " {'word': 'i', 'start_time': 54.97, 'end_time': 55.08},\n",
       " {'word': 'clicked', 'start_time': 55.08, 'end_time': 55.35},\n",
       " {'word': 'the', 'start_time': 55.35, 'end_time': 55.47},\n",
       " {'word': 'map', 'start_time': 55.47, 'end_time': 61.41},\n",
       " {'word': 'looks', 'start_time': 61.41, 'end_time': 61.68},\n",
       " {'word': 'like', 'start_time': 61.68, 'end_time': 61.83},\n",
       " {'word': \"it's\", 'start_time': 61.83, 'end_time': 62.02},\n",
       " {'word': 'not', 'start_time': 62.02, 'end_time': 62.23},\n",
       " {'word': 'hiding', 'start_time': 62.23, 'end_time': 62.62},\n",
       " {'word': 'now', 'start_time': 62.62, 'end_time': 63.88},\n",
       " {'word': 'before', 'start_time': 63.88, 'end_time': 64.24},\n",
       " {'word': 'i', 'start_time': 64.24, 'end_time': 64.34},\n",
       " {'word': 'was', 'start_time': 64.34, 'end_time': 64.48},\n",
       " {'word': 'hiding', 'start_time': 64.48, 'end_time': 64.81},\n",
       " {'word': 'behind', 'start_time': 64.81, 'end_time': 67.92},\n",
       " {'word': 'alright', 'start_time': 67.92, 'end_time': 68.39},\n",
       " {'word': \"what's\", 'start_time': 68.39, 'end_time': 68.8},\n",
       " {'word': 'weent', 'start_time': 68.99, 'end_time': 68.99},\n",
       " {'word': 'weent', 'start_time': 68.99, 'end_time': 68.99}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_timestamps = remove_stutters(with_times, time_format=True)\n",
    "new_timestamps = common_corrections(with_times, time_format=True)\n",
    "new_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unknown-jason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "124\n",
      "this video mis show what we need to do in order to have a two screen monitor set up running a vepad spow client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke lides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it's not hiding now before i was hiding behind alright what's weent weent \n"
     ]
    }
   ],
   "source": [
    "print(len(common_text.split()))\n",
    "print(len(new_timestamps))\n",
    "temp_trans = ''\n",
    "for word in new_timestamps:\n",
    "    temp_trans = temp_trans + word['word'] + ' '\n",
    "    \n",
    "print(temp_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "regulation-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acronym_fix(input_text, time_format=False, input_stamps = None):\n",
    "    import re\n",
    "    regex = r\"\\s+([a-z]\\s){3,}\" #lowercase acronyms with at least 3 letters\n",
    "    matches = re.finditer(regex, input_text, re.MULTILINE)\n",
    "    acro_text = input_text\n",
    "\n",
    "    replace_letters = []\n",
    "    replacements = []\n",
    "\n",
    "    for matchNum, match in enumerate(matches, start=1): \n",
    "        print(\"Match {matchNum} was found at {start}-{end}: {match}\".format(matchNum = matchNum, start = match.start(), end = match.end(), match = match.group()))\n",
    "        print(\"Will be subsituted for:{sub}\".format(sub=' '+match.group().replace(' ', '').upper()))\n",
    "        for letter in match.group():\n",
    "            replace_letters.append(letter)\n",
    "        acro_text = acro_text.replace(match.group(),' '+match.group().replace(' ', '').upper()+\" \")\n",
    "        replacements.append(match.group().replace(' ', '').upper())\n",
    "        \n",
    "    if not time_format:\n",
    "        return acro_text, replacements\n",
    "\n",
    "    #filter spaces\n",
    "    replace_letters = list(filter(lambda a: a != ' ', replace_letters))\n",
    "\n",
    "    print('Replace_letters: ', replace_letters)\n",
    "    print('Replacements: ', replacements)\n",
    "\n",
    "    count = 0\n",
    "    used = 0\n",
    "    for word_dict in input_stamps:\n",
    "        if word_dict['word'] in replace_letters:\n",
    "            if input_stamps[count+1]['word'] and input_stamps[count+2]['word'] in replace_letters:\n",
    "                acro_length = len(replacements[used])\n",
    "\n",
    "                stored_start = input_stamps[count]['start_time']\n",
    "                print('Stored start: ', stored_start)\n",
    "                stored_end = input_stamps[count+acro_length-1]['end_time']\n",
    "                print('Stored end: ', stored_end)\n",
    "\n",
    "                word_dict['word'] = replacements[used]\n",
    "                word_dict['end_time'] = stored_end\n",
    "\n",
    "                for i in range(1, acro_length):\n",
    "                    input_stamps.pop(count+1)\n",
    "                used+=1\n",
    "        count+=1\n",
    "    return input_stamps, replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "outstanding-broad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replace_letters:  []\n",
      "Replacements:  []\n"
     ]
    }
   ],
   "source": [
    "acro_text, acros = acronym_fix(common_text)\n",
    "print()\n",
    "acro_stamps, acros = acronym_fix(common_text, time_format=True, input_stamps=new_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "artificial-listing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this video mis show what we need to do in order to have a two screen monitor set up running a vepad spow client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke lides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it's not hiding now before i was hiding behind alright what's can weent\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acro_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "occupational-think",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'this', 'start_time': 0, 'end_time': 0.8},\n",
       " {'word': 'video', 'start_time': 0.8, 'end_time': 1.17},\n",
       " {'word': 'mis', 'start_time': 1.17, 'end_time': 1.41},\n",
       " {'word': 'show', 'start_time': 1.41, 'end_time': 2.63},\n",
       " {'word': 'what', 'start_time': 2.63, 'end_time': 3.12},\n",
       " {'word': 'we', 'start_time': 3.12, 'end_time': 3.27},\n",
       " {'word': 'need', 'start_time': 3.27, 'end_time': 3.46},\n",
       " {'word': 'to', 'start_time': 3.46, 'end_time': 3.59},\n",
       " {'word': 'do', 'start_time': 3.59, 'end_time': 4.05},\n",
       " {'word': 'in', 'start_time': 4.05, 'end_time': 4.52},\n",
       " {'word': 'order', 'start_time': 4.52, 'end_time': 4.85},\n",
       " {'word': 'to', 'start_time': 4.85, 'end_time': 5.0},\n",
       " {'word': 'have', 'start_time': 5.0, 'end_time': 5.22},\n",
       " {'word': 'a', 'start_time': 5.22, 'end_time': 5.35},\n",
       " {'word': 'two', 'start_time': 5.35, 'end_time': 5.6},\n",
       " {'word': 'screen', 'start_time': 5.6, 'end_time': 5.96},\n",
       " {'word': 'monitor', 'start_time': 5.96, 'end_time': 6.41},\n",
       " {'word': 'set', 'start_time': 6.41, 'end_time': 6.64},\n",
       " {'word': 'up', 'start_time': 6.64, 'end_time': 7.5},\n",
       " {'word': 'running', 'start_time': 7.5, 'end_time': 8.19},\n",
       " {'word': 'a', 'start_time': 8.19, 'end_time': 8.37},\n",
       " {'word': 'vepad', 'start_time': 8.74, 'end_time': 9.46},\n",
       " {'word': 'spow', 'start_time': 9.46, 'end_time': 9.81},\n",
       " {'word': 'client', 'start_time': 9.81, 'end_time': 11.12},\n",
       " {'word': 'right', 'start_time': 11.12, 'end_time': 11.43},\n",
       " {'word': 'now', 'start_time': 11.43, 'end_time': 11.62},\n",
       " {'word': 'i', 'start_time': 11.62, 'end_time': 11.77},\n",
       " {'word': 'have', 'start_time': 11.77, 'end_time': 12.61},\n",
       " {'word': 'just', 'start_time': 12.61, 'end_time': 13.41},\n",
       " {'word': 'one', 'start_time': 13.41, 'end_time': 13.69},\n",
       " {'word': 'stream', 'start_time': 13.69, 'end_time': 14.08},\n",
       " {'word': 'going', 'start_time': 14.08, 'end_time': 16.4},\n",
       " {'word': 'we', 'start_time': 16.81, 'end_time': 17.24},\n",
       " {'word': 'hid', 'start_time': 17.24, 'end_time': 17.41},\n",
       " {'word': 'the', 'start_time': 17.41, 'end_time': 17.53},\n",
       " {'word': 'reload', 'start_time': 17.53, 'end_time': 17.97},\n",
       " {'word': 'here', 'start_time': 17.97, 'end_time': 19.73},\n",
       " {'word': 'so', 'start_time': 19.73, 'end_time': 20.02},\n",
       " {'word': 'i', 'start_time': 20.02, 'end_time': 20.13},\n",
       " {'word': 'have', 'start_time': 20.13, 'end_time': 20.26},\n",
       " {'word': 'my', 'start_time': 20.26, 'end_time': 20.38},\n",
       " {'word': 'map', 'start_time': 20.38, 'end_time': 20.64},\n",
       " {'word': 'on', 'start_time': 20.64, 'end_time': 20.74},\n",
       " {'word': 'the', 'start_time': 20.74, 'end_time': 20.86},\n",
       " {'word': 'left', 'start_time': 20.86, 'end_time': 21.09},\n",
       " {'word': 'stream', 'start_time': 21.09, 'end_time': 21.42},\n",
       " {'word': 'which', 'start_time': 21.42, 'end_time': 21.63},\n",
       " {'word': 'is', 'start_time': 21.63, 'end_time': 21.81},\n",
       " {'word': 'not', 'start_time': 21.81, 'end_time': 22.03},\n",
       " {'word': 'the', 'start_time': 22.03, 'end_time': 22.32},\n",
       " {'word': 'main', 'start_time': 22.32, 'end_time': 22.76},\n",
       " {'word': 'screen', 'start_time': 22.76, 'end_time': 23.1},\n",
       " {'word': 'that', 'start_time': 23.1, 'end_time': 23.27},\n",
       " {'word': 'my', 'start_time': 23.27, 'end_time': 23.54},\n",
       " {'word': 'spoke', 'start_time': 23.54, 'end_time': 24.06},\n",
       " {'word': 'lides', 'start_time': 24.06, 'end_time': 24.46},\n",
       " {'word': 'running', 'start_time': 24.46, 'end_time': 24.73},\n",
       " {'word': 'on', 'start_time': 24.73, 'end_time': 27.37},\n",
       " {'word': 'so', 'start_time': 27.37, 'end_time': 27.69},\n",
       " {'word': 'mi', 'start_time': 27.69, 'end_time': 27.88},\n",
       " {'word': 'see', 'start_time': 27.88, 'end_time': 28.04},\n",
       " {'word': 'if', 'start_time': 28.04, 'end_time': 28.14},\n",
       " {'word': 'i', 'start_time': 28.14, 'end_time': 28.23},\n",
       " {'word': 'can', 'start_time': 28.23, 'end_time': 28.37},\n",
       " {'word': 'drag', 'start_time': 28.37, 'end_time': 28.63},\n",
       " {'word': 'it', 'start_time': 28.63, 'end_time': 28.74},\n",
       " {'word': 'over', 'start_time': 28.74, 'end_time': 29.79},\n",
       " {'word': 'so', 'start_time': 29.79, 'end_time': 30.22},\n",
       " {'word': 'it', 'start_time': 30.22, 'end_time': 30.33},\n",
       " {'word': 'looks', 'start_time': 30.33, 'end_time': 30.51},\n",
       " {'word': 'like', 'start_time': 30.51, 'end_time': 30.64},\n",
       " {'word': 'when', 'start_time': 30.64, 'end_time': 30.79},\n",
       " {'word': 'i', 'start_time': 30.79, 'end_time': 30.9},\n",
       " {'word': 'drag', 'start_time': 30.9, 'end_time': 31.14},\n",
       " {'word': 'it', 'start_time': 31.14, 'end_time': 31.27},\n",
       " {'word': 'to', 'start_time': 31.27, 'end_time': 31.4},\n",
       " {'word': 'the', 'start_time': 31.4, 'end_time': 31.54},\n",
       " {'word': 'left', 'start_time': 31.54, 'end_time': 32.47},\n",
       " {'word': \"it's\", 'start_time': 32.47, 'end_time': 32.65},\n",
       " {'word': 'going', 'start_time': 32.65, 'end_time': 32.93},\n",
       " {'word': 'behind', 'start_time': 32.93, 'end_time': 33.27},\n",
       " {'word': 'the', 'start_time': 33.27, 'end_time': 33.4},\n",
       " {'word': 'map', 'start_time': 33.4, 'end_time': 37.0},\n",
       " {'word': 'she', 'start_time': 37.0, 'end_time': 37.18},\n",
       " {'word': 'is', 'start_time': 37.18, 'end_time': 37.35},\n",
       " {'word': 'behind', 'start_time': 37.35, 'end_time': 37.81},\n",
       " {'word': 'here', 'start_time': 37.81, 'end_time': 38.87},\n",
       " {'word': 'i', 'start_time': 38.87, 'end_time': 39.07},\n",
       " {'word': 'open', 'start_time': 39.07, 'end_time': 39.38},\n",
       " {'word': 'this', 'start_time': 39.38, 'end_time': 46.35},\n",
       " {'word': 'really', 'start_time': 46.35, 'end_time': 46.7},\n",
       " {'word': 'what', 'start_time': 46.7, 'end_time': 46.88},\n",
       " {'word': 'i', 'start_time': 46.88, 'end_time': 47.0},\n",
       " {'word': 'want', 'start_time': 47.0, 'end_time': 47.17},\n",
       " {'word': 'to', 'start_time': 47.17, 'end_time': 47.29},\n",
       " {'word': 'show', 'start_time': 47.29, 'end_time': 47.55},\n",
       " {'word': 'is', 'start_time': 47.55, 'end_time': 51.29},\n",
       " {'word': 'when', 'start_time': 51.29, 'end_time': 51.48},\n",
       " {'word': 'i', 'start_time': 51.48, 'end_time': 51.6},\n",
       " {'word': 'have', 'start_time': 51.6, 'end_time': 51.79},\n",
       " {'word': 'my', 'start_time': 51.79, 'end_time': 51.99},\n",
       " {'word': 'video', 'start_time': 51.99, 'end_time': 52.4},\n",
       " {'word': 'player', 'start_time': 52.4, 'end_time': 52.69},\n",
       " {'word': 'up', 'start_time': 52.69, 'end_time': 54.76},\n",
       " {'word': 'and', 'start_time': 54.76, 'end_time': 54.97},\n",
       " {'word': 'i', 'start_time': 54.97, 'end_time': 55.08},\n",
       " {'word': 'clicked', 'start_time': 55.08, 'end_time': 55.35},\n",
       " {'word': 'the', 'start_time': 55.35, 'end_time': 55.47},\n",
       " {'word': 'map', 'start_time': 55.47, 'end_time': 61.41},\n",
       " {'word': 'looks', 'start_time': 61.41, 'end_time': 61.68},\n",
       " {'word': 'like', 'start_time': 61.68, 'end_time': 61.83},\n",
       " {'word': \"it's\", 'start_time': 61.83, 'end_time': 62.02},\n",
       " {'word': 'not', 'start_time': 62.02, 'end_time': 62.23},\n",
       " {'word': 'hiding', 'start_time': 62.23, 'end_time': 62.62},\n",
       " {'word': 'now', 'start_time': 62.62, 'end_time': 63.88},\n",
       " {'word': 'before', 'start_time': 63.88, 'end_time': 64.24},\n",
       " {'word': 'i', 'start_time': 64.24, 'end_time': 64.34},\n",
       " {'word': 'was', 'start_time': 64.34, 'end_time': 64.48},\n",
       " {'word': 'hiding', 'start_time': 64.48, 'end_time': 64.81},\n",
       " {'word': 'behind', 'start_time': 64.81, 'end_time': 67.92},\n",
       " {'word': 'alright', 'start_time': 67.92, 'end_time': 68.39},\n",
       " {'word': \"what's\", 'start_time': 68.39, 'end_time': 68.8},\n",
       " {'word': 'weent', 'start_time': 68.99, 'end_time': 68.99},\n",
       " {'word': 'weent', 'start_time': 68.99, 'end_time': 68.99}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acro_stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "generic-webcam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"this video mis show what we need to do in order to have a two screen monitor set up running a vepad spow client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke lides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it's not hiding now before i was hiding behind alright what's weent weent \""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(acro_text.split()))\n",
    "print(len(acro_stamps))\n",
    "temp_trans = ''\n",
    "for word in acro_stamps:\n",
    "    temp_trans = temp_trans + word['word'] + ' '\n",
    "    \n",
    "temp_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-memphis",
   "metadata": {},
   "source": [
    "## NeMo punct + cap test (this would go before neuspell in pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "written-thumbnail",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" this video mis show what we need to do in order to have a two screen monitor set up running a vepad spow client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke lides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it's not hiding now before i was hiding behind alright what's can weent\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation._cfg.dataset.max_seq_length = 1000\n",
    "\n",
    "def text_to_groups(input):\n",
    "    text_split = input.split()\n",
    "    split_groups = []\n",
    "    working_string = ''\n",
    "    for word in text_split:\n",
    "        if len(working_string+word)>1000:\n",
    "            split_groups.append(working_string)\n",
    "            working_string = ''\n",
    "        working_string = working_string + ' ' + word\n",
    "\n",
    "    split_groups.append(working_string)\n",
    "    return split_groups\n",
    "\n",
    "split_groups = text_to_groups(acro_text)\n",
    "split_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "english-positive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_model:377] Using batch size 1 for inference\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:134] Max length: 137\n",
      "[NeMo I 2021-05-26 12:31:48 data_preprocessing:297] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2021-05-26 12:31:48 data_preprocessing:299] Min: 137 |                  Max: 137 |                  Mean: 137.0 |                  Median: 137.0\n",
      "[NeMo I 2021-05-26 12:31:48 data_preprocessing:305] 75 percentile: 137.00\n",
      "[NeMo I 2021-05-26 12:31:48 data_preprocessing:306] 99 percentile: 137.00\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:165] 0 are longer than 137\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:168] *** Example ***\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:169] i: 0\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:170] subtokens: [CLS] this video mis show what we need to do in order to have a two screen monitor set up running a ve ##pad sp ##ow client right now i have just one stream going we hid the re ##load here so i have my map on the left stream which is not the main screen that my spoke lid ##es running on so mi see if i can drag it over so it looks like when i drag it to the left it ' s going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it ' s not hiding now before i was hiding behind alright what ' s can wee ##nt [SEP]\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:171] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:172] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2021-05-26 12:31:48 punctuation_capitalization_dataset:173] subtokens_mask: 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0\n"
     ]
    }
   ],
   "source": [
    "def recapitalize_acros(input_text, acronyms):\n",
    "    output_text = input_text\n",
    "    for replacement in acronyms:\n",
    "        output_text = re.sub(replacement.lower().capitalize(), replacement, output_text)\n",
    "    return output_text\n",
    "\n",
    "def decapitalize(str):\n",
    "    return str[:1].lower() + str[1:]\n",
    "\n",
    "restored_groups = []\n",
    "for word_group in split_groups:\n",
    "    res = punctuation.add_punctuation_capitalization(queries=[word_group])\n",
    "    text = res[0]\n",
    "    restored_groups.append(text)\n",
    "restored_text = ''\n",
    "for word_group in restored_groups:\n",
    "    restored_text = restored_text + decapitalize(word_group[:-1]) + \" \"\n",
    "restored_text = recapitalize_acros(restored_text, acros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "intimate-program",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this video mis show what we need to do in order to have a two screen monitor set up running a Vepad Spow client. Right now, I have just one stream going. We hid the reload here, So I have my map on the left stream, which is not the main screen that my spoke lides running on. so Mi, see if I can drag it over. So it looks like when I drag it to the left, it's going behind the map. She is behind here. I open this. Really, what I want to show is when I have my video player up and I clicked The map Looks like it's not hiding now before I was hiding behind. Alright, what's can weent \n"
     ]
    }
   ],
   "source": [
    "print(restored_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-situation",
   "metadata": {},
   "source": [
    "## SpellCheck Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "mysterious-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import contextualSpellCheck\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"contextual spellchecker\", config={\"max_edit_dist\": 100})\n",
    "doc = nlp(\"Income was $9.4 milion compared to the prior year of $2.7 milion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cross-timber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "{milion: 'million', milion: 'million'}\n",
      "Income was $9.4 million compared to the prior year of $2.7 million.\n",
      "{milion: [('million', 0.59423), ('billion', 0.24349), (',', 0.08809), ('trillion', 0.01835), ('Million', 0.00826), ('%', 0.00672), ('##M', 0.00591), ('annually', 0.0038), ('##B', 0.00205), ('USD', 0.00113)], milion: [('billion', 0.65934), ('million', 0.26185), ('trillion', 0.05391), ('##M', 0.0051), ('Million', 0.00425), ('##B', 0.00268), ('USD', 0.00153), ('##b', 0.00077), ('millions', 0.00059), ('%', 0.00041)]}\n",
      "\n",
      "Token Extentions\n",
      "True\n",
      "million\n",
      "[('million', 0.59423), ('billion', 0.24349), (',', 0.08809), ('trillion', 0.01835), ('Million', 0.00826), ('%', 0.00672), ('##M', 0.00591), ('annually', 0.0038), ('##B', 0.00205), ('USD', 0.00113)]\n",
      "\n",
      "Span Extensions\n",
      "True\n",
      "{$: [], 9.4: [], milion: [('million', 0.59423), ('billion', 0.24349), (',', 0.08809), ('trillion', 0.01835), ('Million', 0.00826), ('%', 0.00672), ('##M', 0.00591), ('annually', 0.0038), ('##B', 0.00205), ('USD', 0.00113)], compared: []}\n"
     ]
    }
   ],
   "source": [
    "####DEMO OF ALL spacy/contextualSpellCheck functionality\n",
    "\n",
    "# Doc Extension\n",
    "print(doc._.contextual_spellCheck)\n",
    "print(doc._.performed_spellCheck)\n",
    "print(doc._.suggestions_spellCheck)\n",
    "print(doc._.outcome_spellCheck)\n",
    "print(doc._.score_spellCheck)\n",
    "\n",
    "print()\n",
    "print('Token Extentions')\n",
    "# Token Extention\n",
    "print(doc[4]._.get_require_spellCheck)\n",
    "print(doc[4]._.get_suggestion_spellCheck)\n",
    "print(doc[4]._.score_spellCheck)\n",
    "\n",
    "print()\n",
    "print('Span Extensions')\n",
    "# Span Extention\n",
    "print(doc[2:6]._.get_has_spellCheck)\n",
    "print(doc[2:6]._.score_spellCheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "federal-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextualSpellCheck\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "contextualSpellCheck.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sharp-scotland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top suggestion for \" milion \" --> ('million', 0.59423)\n",
      "Top suggestion for \" milion \" --> ('billion', 0.65934)\n"
     ]
    }
   ],
   "source": [
    "for word in doc._.score_spellCheck:\n",
    "    print('Top suggestion for \"', str(word), '\" -->',doc._.score_spellCheck[word][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "yellow-sampling",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this video mis show what we need to do in order to have a two screen monitor set up running a vepad spow client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke is running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it's not hiding now before i was hiding behind alright what's weent weent \""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_topchecks(input_text):\n",
    "    output_text = input_text\n",
    "    nlp_doc = nlp(output_text)\n",
    "    for word in nlp_doc._.score_spellCheck:\n",
    "        if round(nlp_doc._.score_spellCheck[word][0][1], 3)>0.800:\n",
    "            replace_word = nlp_doc._.score_spellCheck[word][0][0]\n",
    "            output_text = re.sub(str(word), replace_word, output_text)\n",
    "    return output_text\n",
    "\n",
    "after_check = replace_topchecks(temp_trans)\n",
    "after_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "understanding-marker",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech.neuspell'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-5e41acedb8b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuspell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneuspell\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSclstmChecker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mchecker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSclstmChecker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mchecker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchecker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"elmo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mchecker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./speech/neuspell/data/checkpoints/elmoscrnn-probwordnoise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'speech.neuspell'"
     ]
    }
   ],
   "source": [
    "from speech.neuspell.neuspell import SclstmChecker\n",
    "checker = SclstmChecker()\n",
    "checker = checker.add_(\"elmo\", at=\"input\")\n",
    "checker.from_pretrained(\"./speech/neuspell/data/checkpoints/elmoscrnn-probwordnoise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "outdoor-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postspell(input_text):\n",
    "    output_text = re.sub(r\"\\s'\",r\"'\", input_text)\n",
    "    output_text = output_text.replace(' .', '.')\n",
    "    output_text = output_text.replace(' ,', ',')\n",
    "    output_text = output_text.replace(' ?', '?')\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "def neuspell_correct(input_text, spell_checker):\n",
    "    output_text = spell_checker.correct(input_text)\n",
    "    output_text = postspell(output_text)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "direct-theorem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'this'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'video'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'mis'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'show'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'what'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'we'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'need'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'to'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'do'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'in'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'order'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'to'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'have'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'a'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'two'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'screen'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'monitor'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'set'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'up'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'running'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'a'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'Vepad'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'Spow'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'client'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'Right'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'now'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ','. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'have'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'just'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'one'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'stream'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'going'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'We'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'hid'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'the'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'reload'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'here'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ','. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'So'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'have'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'my'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'map'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'on'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'the'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'left'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'stream'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ','. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'which'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'is'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'not'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'the'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'main'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'screen'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'that'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'my'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'spoke'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'lides'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'running'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'on'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'so'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'Mi'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ','. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'see'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'if'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'can'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'drag'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'it'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'over'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'So'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'it'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'looks'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'like'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'when'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'drag'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'it'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'to'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'the'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'left'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ','. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'it'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ''s'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'going'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'behind'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'the'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'map'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'She'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'is'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'behind'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'here'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'open'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'this'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'Really'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ','. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'what'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'want'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'to'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'show'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'is'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'when'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'have'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'my'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'video'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'player'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'up'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'and'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'clicked'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'the'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'mapt'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'looks'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'like'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'it'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ''s'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'not'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'hiding'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'now'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'before'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'I'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'was'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'hiding'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'behind'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token '.'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'Alright'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ','. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'what'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token ''s'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'can'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "[W108] The rule-based lemmatizer did not find POS annotation for the token 'weent'. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n"
     ]
    }
   ],
   "source": [
    "corrected = neuspell_correct(restored_text, checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "decent-burke",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this video is show what we need to do in order to have a two screen monitor set up running a Vepad Spow client. Right now, I have just one stream going. We hid the reload here, So I have my map on the left stream, which is not the main screen that my spoke ladies running on. so Me, see if I can drag it over. So it looks like when I drag it to the left, it's going behind the map. She is behind here. I open this. Really, what I want to show is when I have my video player up and I clicked the map. looks like it's not hiding now before I was hiding behind. Alright, what's can went\n"
     ]
    }
   ],
   "source": [
    "print(corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "parental-target",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "124\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "print(len(after_check.split()))\n",
    "print(len(corrected.split()))\n",
    "print(len(acro_stamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "original-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this video mis show what we need to do in order to have a two screen monitor set up running a vepad spow client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke lides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the mapt looks like it's not hiding now before i was hiding behind alright what's weent weent \""
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_trans = ''\n",
    "for word in new_timestamps:\n",
    "    temp_trans = temp_trans + word['word'] + ' '\n",
    "    \n",
    "temp_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "compressed-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconnect_timetext(text, timestamps):\n",
    "    assert len(text.split())==len(timestamps), 'Inputs should have same number of words. Length of text: {}, Length of timestamps: {}'.format(len(text.split()), len(timestamps))\n",
    "    word_list = text.split()\n",
    "    word_count = 0\n",
    "    for word_stamp in timestamps:\n",
    "        word_stamp['word'] = word_list[word_count]\n",
    "        word_count+=1\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "spare-knowing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'this', 'start_time': 0, 'end_time': 0.8},\n",
       " {'word': 'video', 'start_time': 0.8, 'end_time': 1.17},\n",
       " {'word': 'mis', 'start_time': 1.17, 'end_time': 1.41},\n",
       " {'word': 'show', 'start_time': 1.41, 'end_time': 2.63},\n",
       " {'word': 'what', 'start_time': 2.63, 'end_time': 3.12},\n",
       " {'word': 'we', 'start_time': 3.12, 'end_time': 3.27},\n",
       " {'word': 'need', 'start_time': 3.27, 'end_time': 3.46},\n",
       " {'word': 'to', 'start_time': 3.46, 'end_time': 3.59},\n",
       " {'word': 'do', 'start_time': 3.59, 'end_time': 4.05},\n",
       " {'word': 'in', 'start_time': 4.05, 'end_time': 4.52},\n",
       " {'word': 'order', 'start_time': 4.52, 'end_time': 4.85},\n",
       " {'word': 'to', 'start_time': 4.85, 'end_time': 5.0},\n",
       " {'word': 'have', 'start_time': 5.0, 'end_time': 5.22},\n",
       " {'word': 'a', 'start_time': 5.22, 'end_time': 5.35},\n",
       " {'word': 'two', 'start_time': 5.35, 'end_time': 5.6},\n",
       " {'word': 'screen', 'start_time': 5.6, 'end_time': 5.96},\n",
       " {'word': 'monitor', 'start_time': 5.96, 'end_time': 6.41},\n",
       " {'word': 'set', 'start_time': 6.41, 'end_time': 6.64},\n",
       " {'word': 'up', 'start_time': 6.64, 'end_time': 7.5},\n",
       " {'word': 'running', 'start_time': 7.5, 'end_time': 8.19},\n",
       " {'word': 'a', 'start_time': 8.19, 'end_time': 8.37},\n",
       " {'word': 'Vepad', 'start_time': 8.74, 'end_time': 9.46},\n",
       " {'word': 'Spow', 'start_time': 9.46, 'end_time': 9.81},\n",
       " {'word': 'client.', 'start_time': 9.81, 'end_time': 11.12},\n",
       " {'word': 'Right', 'start_time': 11.12, 'end_time': 11.43},\n",
       " {'word': 'now,', 'start_time': 11.43, 'end_time': 11.62},\n",
       " {'word': 'I', 'start_time': 11.62, 'end_time': 11.77},\n",
       " {'word': 'have', 'start_time': 11.77, 'end_time': 12.61},\n",
       " {'word': 'just', 'start_time': 12.61, 'end_time': 13.41},\n",
       " {'word': 'one', 'start_time': 13.41, 'end_time': 13.69},\n",
       " {'word': 'stream', 'start_time': 13.69, 'end_time': 14.08},\n",
       " {'word': 'going.', 'start_time': 14.08, 'end_time': 16.4},\n",
       " {'word': 'We', 'start_time': 16.81, 'end_time': 17.24},\n",
       " {'word': 'hid', 'start_time': 17.24, 'end_time': 17.41},\n",
       " {'word': 'the', 'start_time': 17.41, 'end_time': 17.53},\n",
       " {'word': 'reload', 'start_time': 17.53, 'end_time': 17.97},\n",
       " {'word': 'here,', 'start_time': 17.97, 'end_time': 19.73},\n",
       " {'word': 'So', 'start_time': 19.73, 'end_time': 20.02},\n",
       " {'word': 'I', 'start_time': 20.02, 'end_time': 20.13},\n",
       " {'word': 'have', 'start_time': 20.13, 'end_time': 20.26},\n",
       " {'word': 'my', 'start_time': 20.26, 'end_time': 20.38},\n",
       " {'word': 'map', 'start_time': 20.38, 'end_time': 20.64},\n",
       " {'word': 'on', 'start_time': 20.64, 'end_time': 20.74},\n",
       " {'word': 'the', 'start_time': 20.74, 'end_time': 20.86},\n",
       " {'word': 'left', 'start_time': 20.86, 'end_time': 21.09},\n",
       " {'word': 'stream,', 'start_time': 21.09, 'end_time': 21.42},\n",
       " {'word': 'which', 'start_time': 21.42, 'end_time': 21.63},\n",
       " {'word': 'is', 'start_time': 21.63, 'end_time': 21.81},\n",
       " {'word': 'not', 'start_time': 21.81, 'end_time': 22.03},\n",
       " {'word': 'the', 'start_time': 22.03, 'end_time': 22.32},\n",
       " {'word': 'main', 'start_time': 22.32, 'end_time': 22.76},\n",
       " {'word': 'screen', 'start_time': 22.76, 'end_time': 23.1},\n",
       " {'word': 'that', 'start_time': 23.1, 'end_time': 23.27},\n",
       " {'word': 'my', 'start_time': 23.27, 'end_time': 23.54},\n",
       " {'word': 'spoke', 'start_time': 23.54, 'end_time': 24.06},\n",
       " {'word': 'is', 'start_time': 24.06, 'end_time': 24.46},\n",
       " {'word': 'running', 'start_time': 24.46, 'end_time': 24.73},\n",
       " {'word': 'on.', 'start_time': 24.73, 'end_time': 27.37},\n",
       " {'word': 'so', 'start_time': 27.37, 'end_time': 27.69},\n",
       " {'word': 'Mi,', 'start_time': 27.69, 'end_time': 27.88},\n",
       " {'word': 'see', 'start_time': 27.88, 'end_time': 28.04},\n",
       " {'word': 'if', 'start_time': 28.04, 'end_time': 28.14},\n",
       " {'word': 'I', 'start_time': 28.14, 'end_time': 28.23},\n",
       " {'word': 'can', 'start_time': 28.23, 'end_time': 28.37},\n",
       " {'word': 'drag', 'start_time': 28.37, 'end_time': 28.63},\n",
       " {'word': 'it', 'start_time': 28.63, 'end_time': 28.74},\n",
       " {'word': 'over.', 'start_time': 28.74, 'end_time': 29.79},\n",
       " {'word': 'So', 'start_time': 29.79, 'end_time': 30.22},\n",
       " {'word': 'it', 'start_time': 30.22, 'end_time': 30.33},\n",
       " {'word': 'looks', 'start_time': 30.33, 'end_time': 30.51},\n",
       " {'word': 'like', 'start_time': 30.51, 'end_time': 30.64},\n",
       " {'word': 'when', 'start_time': 30.64, 'end_time': 30.79},\n",
       " {'word': 'I', 'start_time': 30.79, 'end_time': 30.9},\n",
       " {'word': 'drag', 'start_time': 30.9, 'end_time': 31.14},\n",
       " {'word': 'it', 'start_time': 31.14, 'end_time': 31.27},\n",
       " {'word': 'to', 'start_time': 31.27, 'end_time': 31.4},\n",
       " {'word': 'the', 'start_time': 31.4, 'end_time': 31.54},\n",
       " {'word': 'left,', 'start_time': 31.54, 'end_time': 32.47},\n",
       " {'word': \"it's\", 'start_time': 32.47, 'end_time': 32.65},\n",
       " {'word': 'going', 'start_time': 32.65, 'end_time': 32.93},\n",
       " {'word': 'behind', 'start_time': 32.93, 'end_time': 33.27},\n",
       " {'word': 'the', 'start_time': 33.27, 'end_time': 33.4},\n",
       " {'word': 'map.', 'start_time': 33.4, 'end_time': 37.0},\n",
       " {'word': 'She', 'start_time': 37.0, 'end_time': 37.18},\n",
       " {'word': 'is', 'start_time': 37.18, 'end_time': 37.35},\n",
       " {'word': 'behind', 'start_time': 37.35, 'end_time': 37.81},\n",
       " {'word': 'here.', 'start_time': 37.81, 'end_time': 38.87},\n",
       " {'word': 'I', 'start_time': 38.87, 'end_time': 39.07},\n",
       " {'word': 'open', 'start_time': 39.07, 'end_time': 39.38},\n",
       " {'word': 'this.', 'start_time': 39.38, 'end_time': 46.35},\n",
       " {'word': 'Really,', 'start_time': 46.35, 'end_time': 46.7},\n",
       " {'word': 'what', 'start_time': 46.7, 'end_time': 46.88},\n",
       " {'word': 'I', 'start_time': 46.88, 'end_time': 47.0},\n",
       " {'word': 'want', 'start_time': 47.0, 'end_time': 47.17},\n",
       " {'word': 'to', 'start_time': 47.17, 'end_time': 47.29},\n",
       " {'word': 'show', 'start_time': 47.29, 'end_time': 47.55},\n",
       " {'word': 'is', 'start_time': 47.55, 'end_time': 51.29},\n",
       " {'word': 'when', 'start_time': 51.29, 'end_time': 51.48},\n",
       " {'word': 'I', 'start_time': 51.48, 'end_time': 51.6},\n",
       " {'word': 'have', 'start_time': 51.6, 'end_time': 51.79},\n",
       " {'word': 'my', 'start_time': 51.79, 'end_time': 51.99},\n",
       " {'word': 'video', 'start_time': 51.99, 'end_time': 52.4},\n",
       " {'word': 'player', 'start_time': 52.4, 'end_time': 52.69},\n",
       " {'word': 'up', 'start_time': 52.69, 'end_time': 54.76},\n",
       " {'word': 'and', 'start_time': 54.76, 'end_time': 54.97},\n",
       " {'word': 'I', 'start_time': 54.97, 'end_time': 55.08},\n",
       " {'word': 'clicked', 'start_time': 55.08, 'end_time': 55.35},\n",
       " {'word': 'the', 'start_time': 55.35, 'end_time': 55.47},\n",
       " {'word': 'mapt.', 'start_time': 55.47, 'end_time': 61.41},\n",
       " {'word': 'looks', 'start_time': 61.41, 'end_time': 61.68},\n",
       " {'word': 'like', 'start_time': 61.68, 'end_time': 61.83},\n",
       " {'word': \"it's\", 'start_time': 61.83, 'end_time': 62.02},\n",
       " {'word': 'not', 'start_time': 62.02, 'end_time': 62.23},\n",
       " {'word': 'hiding', 'start_time': 62.23, 'end_time': 62.62},\n",
       " {'word': 'now', 'start_time': 62.62, 'end_time': 63.88},\n",
       " {'word': 'before', 'start_time': 63.88, 'end_time': 64.24},\n",
       " {'word': 'I', 'start_time': 64.24, 'end_time': 64.34},\n",
       " {'word': 'was', 'start_time': 64.34, 'end_time': 64.48},\n",
       " {'word': 'hiding', 'start_time': 64.48, 'end_time': 64.81},\n",
       " {'word': 'behind.', 'start_time': 64.81, 'end_time': 67.92},\n",
       " {'word': 'Alright,', 'start_time': 67.92, 'end_time': 68.39},\n",
       " {'word': \"what's\", 'start_time': 68.39, 'end_time': 68.8},\n",
       " {'word': '.', 'start_time': 68.99, 'end_time': 68.99},\n",
       " {'word': '.', 'start_time': 68.99, 'end_time': 68.99}]"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stamps = reconnect_timetext(after_check, acro_stamps)\n",
    "final_stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "weird-martin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"this video mis show what we need to do in order to have a two screen monitor set up running a Vepad Spow client. Right now, I have just one stream going. We hid the reload here, So I have my map on the left stream, which is not the main screen that my spoke is running on. so Mi, see if I can drag it over. So it looks like when I drag it to the left, it's going behind the map. She is behind here. I open this. Really, what I want to show is when I have my video player up and I clicked the mapt. looks like it's not hiding now before I was hiding behind. Alright, what's . . \""
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_trans = ''\n",
    "for word in final_stamps:\n",
    "    temp_trans = temp_trans + word['word'] + ' '\n",
    "    \n",
    "temp_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "protective-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this video his show what we need to do in order to have a two screen monitor set up running a head show client right now i have just one stream going we hid the reload here so i have my map on the left stream which is not the main screen that my spoke sides running on so mi see if i can drag it over so it looks like when i drag it to the left it's going behind the map she is behind here i open this really what i want to show is when i have my video player up and i clicked the map looks like it's not hiding now before i was hiding behind alright what's went went \n"
     ]
    }
   ],
   "source": [
    "# import TextBlob\n",
    "from textblob import TextBlob\n",
    "\n",
    "gfg = TextBlob(temp_trans)\n",
    "\n",
    "# using TextBlob.correct() method\n",
    "gfg = gfg.correct()\n",
    "\n",
    "print(gfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-crash",
   "metadata": {},
   "source": [
    "## Hugging Face Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "closing-pledge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-1.8.0-py3-none-any.whl (237 kB)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.11.1-py38-none-any.whl (126 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from datasets) (1.2.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from datasets) (20.9)\n",
      "Collecting tqdm<4.50.0,>=4.27\n",
      "  Using cached tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from datasets) (1.20.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.3-py2.py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from datasets) (2021.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from datasets) (2.22.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from datasets) (0.0.8)\n",
      "Collecting pyarrow<4.0.0,>=1.0.0\n",
      "  Using cached pyarrow-3.0.0-cp38-cp38-win_amd64.whl (12.7 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: tqdm, dill, xxhash, pyarrow, multiprocess, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.0\n",
      "    Uninstalling tqdm-4.61.0:\n",
      "      Successfully uninstalled tqdm-4.61.0\n",
      "Successfully installed datasets-1.8.0 dill-0.3.3 multiprocess-0.70.11.1 pyarrow-3.0.0 tqdm-4.56.2 xxhash-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "detectron2 0.4 requires black==21.4b2, but you have black 19.10b0 which is incompatible.\n",
      "detectron2 0.4 requires hydra-core>=1.1.0rc1, but you have hydra-core 1.0.6 which is incompatible.\n",
      "detectron2 0.4 requires omegaconf>=2.1.0rc1, but you have omegaconf 2.1.0.dev22 which is incompatible.\n",
      "allennlp 2.0.1 requires spacy<2.4,>=2.1.0, but you have spacy 3.0.3 which is incompatible.\n",
      "allennlp 2.0.1 requires transformers<4.3,>=4.1, but you have transformers 4.3.2 which is incompatible.\n",
      "nemo-toolkit 1.0.1 requires omegaconf<2.1.0,>=2.0.5, but you have omegaconf 2.1.0.dev22 which is incompatible.\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Blob2\\.conda\\envs\\vbank\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "chicken-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "australian-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "smooth-individual",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset librispeech_asr (C:\\Users\\Blob2\\.cache\\huggingface\\datasets\\librispeech_asr\\clean\\2.1.0\\468ec03677f46a8714ac6b5b64dba02d246a228d92cbbad7f3dc190fa039eab1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855671c5c3f141fba79233741bc361e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wav = './speech/transcribed_audio/ScreenCapture_03-08-2021_113130_202111342334_transcoded.wav'\n",
    "\n",
    "# define function to read in sound file\n",
    "def map_to_array(batch):\n",
    "   # wav = './speech/transcribed_audio/elon.wav'\n",
    "    speech, _ = sf.read(wav)\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "noted-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = tokenizer(ds[\"speech\"][:2], return_tensors=\"pt\", padding=\"longest\").input_values.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "active-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "brazilian-capitol",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 564.00 MiB (GPU 0; 8.00 GiB total capacity; 6.22 GiB already allocated; 0 bytes free; 6.27 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-2bfc9f5c951c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print(type(input_values))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#input_values = torch.DoubleTensor(input_values)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_values, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m         outputs = self.wav2vec2(\n\u001b[0m\u001b[0;32m    796\u001b[0m             \u001b[0minput_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_projection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_values)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mconv_layer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\normalization.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m         return F.group_norm(\n\u001b[0m\u001b[0;32m    246\u001b[0m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[0;32m    247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[1;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2112\u001b[0m         input.size(0) * input.size(1) // num_groups, num_groups]\n\u001b[0;32m   2113\u001b[0m         + list(input.size()[2:]))\n\u001b[1;32m-> 2114\u001b[1;33m     return torch.group_norm(input, num_groups, weight, bias, eps,\n\u001b[0m\u001b[0;32m   2115\u001b[0m                             torch.backends.cudnn.enabled)\n\u001b[0;32m   2116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 564.00 MiB (GPU 0; 8.00 GiB total capacity; 6.22 GiB already allocated; 0 bytes free; 6.27 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "#print(type(input_values))\n",
    "#input_values = torch.DoubleTensor(input_values)\n",
    "logits = model(input_values).logits.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = torch.argmax(logits, axis=-1)\n",
    "transcription = tokenizer.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-completion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-hello",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-bouquet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "decent-jefferson",
   "metadata": {},
   "source": [
    "# YOLO v4 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "armed-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "from yolov4.models.experimental import attempt_load\n",
    "from yolov4.utils.datasets import LoadStreams, LoadImages\n",
    "from yolov4.utils.general import (\n",
    "    check_img_size, non_max_suppression, apply_classifier, scale_coords, xyxy2xywh, plot_one_box, strip_optimizer)\n",
    "from yolov4.utils.torch_utils import select_device, load_classifier, time_synchronized\n",
    "\n",
    "from yolov4.models.models import *\n",
    "from yolov4.models.experimental import *\n",
    "from yolov4.utils.datasets import *\n",
    "from yolov4.utils.general import *\n",
    "\n",
    "from utils import resolve_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "drawn-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce RTX 2070 with Max-Q Design', total_memory=8192MB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set adjustable arguments (for the pruposes of this notebook)\n",
    "\n",
    "source='./yolov4/inference/input'\n",
    "output='./yolov4/inference/output'\n",
    "\n",
    "names = r'./yolov4/names/coco.names'\n",
    "cfg = './yolov4/cfg/yolov4-pacsp-x.cfg'\n",
    "weights = str(r'./yolov4/weights/yolov4-pacsp-x.weights')\n",
    "img_size = 640\n",
    "device = select_device('cuda')\n",
    "\n",
    "webcam = False\n",
    "view_img = False\n",
    "save_txt = True\n",
    "save_img = False\n",
    "\n",
    "conf_thres = 0.4\n",
    "iou_thres = 0.5\n",
    "agnostic_nms = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "brief-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: 408 layers, 9.97511e+07 parameters, 9.97511e+07 gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Darknet(\n",
       "  (module_list): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (Conv2d): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(32, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (Conv2d): Conv2d(32, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (Conv2d): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(40, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (Conv2d): Conv2d(40, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (4): WeightedFeatureFusion()\n",
       "    (5): Sequential(\n",
       "      (Conv2d): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (Conv2d): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (7): FeatureConcat()\n",
       "    (8): Sequential(\n",
       "      (Conv2d): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (Conv2d): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (Conv2d): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (11): WeightedFeatureFusion()\n",
       "    (12): Sequential(\n",
       "      (Conv2d): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (13): Sequential(\n",
       "      (Conv2d): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (14): WeightedFeatureFusion()\n",
       "    (15): Sequential(\n",
       "      (Conv2d): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (16): Sequential(\n",
       "      (Conv2d): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (17): WeightedFeatureFusion()\n",
       "    (18): Sequential(\n",
       "      (Conv2d): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(80, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (19): FeatureConcat()\n",
       "    (20): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (21): Sequential(\n",
       "      (Conv2d): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (22): Sequential(\n",
       "      (Conv2d): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (23): FeatureConcat()\n",
       "    (24): Sequential(\n",
       "      (Conv2d): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (25): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (26): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (27): WeightedFeatureFusion()\n",
       "    (28): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (29): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (30): WeightedFeatureFusion()\n",
       "    (31): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (32): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (33): WeightedFeatureFusion()\n",
       "    (34): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (35): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (36): WeightedFeatureFusion()\n",
       "    (37): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (38): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (39): WeightedFeatureFusion()\n",
       "    (40): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (41): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (42): WeightedFeatureFusion()\n",
       "    (43): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (44): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (45): WeightedFeatureFusion()\n",
       "    (46): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (47): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (48): WeightedFeatureFusion()\n",
       "    (49): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (50): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (51): WeightedFeatureFusion()\n",
       "    (52): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (53): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (54): WeightedFeatureFusion()\n",
       "    (55): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (56): FeatureConcat()\n",
       "    (57): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (58): Sequential(\n",
       "      (Conv2d): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (59): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (60): FeatureConcat()\n",
       "    (61): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (62): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (63): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (64): WeightedFeatureFusion()\n",
       "    (65): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (66): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (67): WeightedFeatureFusion()\n",
       "    (68): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (69): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (70): WeightedFeatureFusion()\n",
       "    (71): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (72): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (73): WeightedFeatureFusion()\n",
       "    (74): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (75): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (76): WeightedFeatureFusion()\n",
       "    (77): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (78): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (79): WeightedFeatureFusion()\n",
       "    (80): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (81): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (82): WeightedFeatureFusion()\n",
       "    (83): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (84): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (85): WeightedFeatureFusion()\n",
       "    (86): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (87): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (88): WeightedFeatureFusion()\n",
       "    (89): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (90): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (91): WeightedFeatureFusion()\n",
       "    (92): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (93): FeatureConcat()\n",
       "    (94): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (95): Sequential(\n",
       "      (Conv2d): Conv2d(640, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1280, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (96): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (97): FeatureConcat()\n",
       "    (98): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (99): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (100): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (101): WeightedFeatureFusion()\n",
       "    (102): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (103): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (104): WeightedFeatureFusion()\n",
       "    (105): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (106): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (107): WeightedFeatureFusion()\n",
       "    (108): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (109): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (110): WeightedFeatureFusion()\n",
       "    (111): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (112): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (113): WeightedFeatureFusion()\n",
       "    (114): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (115): FeatureConcat()\n",
       "    (116): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1280, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (117): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (118): FeatureConcat()\n",
       "    (119): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (120): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (121): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (122): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    (123): FeatureConcat()\n",
       "    (124): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
       "    (125): FeatureConcat()\n",
       "    (126): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
       "    (127): FeatureConcat()\n",
       "    (128): Sequential(\n",
       "      (Conv2d): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (129): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (130): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (131): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (132): FeatureConcat()\n",
       "    (133): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (134): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (135): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (136): FeatureConcat()\n",
       "    (137): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (138): FeatureConcat()\n",
       "    (139): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (140): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (141): FeatureConcat()\n",
       "    (142): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (143): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (144): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (145): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (146): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (147): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (148): FeatureConcat()\n",
       "    (149): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (150): Sequential(\n",
       "      (Conv2d): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (151): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (152): FeatureConcat()\n",
       "    (153): Sequential(\n",
       "      (Conv2d): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (154): FeatureConcat()\n",
       "    (155): Sequential(\n",
       "      (Conv2d): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (156): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (157): FeatureConcat()\n",
       "    (158): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (159): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (160): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (161): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (162): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (163): Sequential(\n",
       "      (Conv2d): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (164): FeatureConcat()\n",
       "    (165): Sequential(\n",
       "      (Conv2d): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(160, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (166): Sequential(\n",
       "      (Conv2d): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (167): Sequential(\n",
       "      (Conv2d): Conv2d(320, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (168): YOLOLayer()\n",
       "    (169): FeatureConcat()\n",
       "    (170): Sequential(\n",
       "      (Conv2d): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (171): FeatureConcat()\n",
       "    (172): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (173): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (174): FeatureConcat()\n",
       "    (175): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (176): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (177): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (178): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (179): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (180): Sequential(\n",
       "      (Conv2d): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (181): FeatureConcat()\n",
       "    (182): Sequential(\n",
       "      (Conv2d): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(320, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (183): Sequential(\n",
       "      (Conv2d): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (184): Sequential(\n",
       "      (Conv2d): Conv2d(640, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (185): YOLOLayer()\n",
       "    (186): FeatureConcat()\n",
       "    (187): Sequential(\n",
       "      (Conv2d): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (188): FeatureConcat()\n",
       "    (189): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (190): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (191): FeatureConcat()\n",
       "    (192): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (193): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (194): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (195): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (196): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (197): Sequential(\n",
       "      (Conv2d): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (198): FeatureConcat()\n",
       "    (199): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(640, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (200): Sequential(\n",
       "      (Conv2d): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (BatchNorm2d): BatchNorm2d(1280, eps=0.0001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "    )\n",
       "    (201): Sequential(\n",
       "      (Conv2d): Conv2d(1280, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (202): YOLOLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model = Darknet(cfg, img_size).cuda()\n",
    "try:\n",
    "    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
    "except:\n",
    "    load_darknet_weights(model, weights)\n",
    "    \n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "promotional-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Dataloader\n",
    "vid_path, vid_writer = None, None\n",
    "if webcam:\n",
    "    view_img = True\n",
    "    cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "    dataset = LoadStreams(source, img_size=img_size)\n",
    "else:\n",
    "    save_img = True\n",
    "    dataset = LoadImages(source, img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "smoking-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names and colors\n",
    "names = load_classes(names)\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "interior-advocacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint1,  0\n",
      "Sequential\n",
      "Checkpoint2,  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 8.00 GiB total capacity; 5.80 GiB already allocated; 28.35 MiB free; 5.87 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-9b365804993f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# init img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'cpu'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# run once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Repos\\VB_AI_Controller\\yolov4\\models\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, augment, verbose)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0maugment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Augment images (inference and test only) https://github.com/ultralytics/yolov3/issues/931\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mimg_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# height, width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Repos\\VB_AI_Controller\\yolov4\\models\\models.py\u001b[0m in \u001b[0;36mforward_once\u001b[1;34m(self, x, augment, verbose)\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# run module directly, i.e. mtype = 'convolutional', 'upsample', 'maxpool', 'batchnorm2d' etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Checkpoint2, '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Checkpoint3, '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    732\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\blob2\\.conda\\envs\\vbank\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 419\u001b[1;33m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[0;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 8.00 GiB total capacity; 5.80 GiB already allocated; 28.35 MiB free; 5.87 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "t0 = time.time()\n",
    "img = torch.zeros((1, 3, img_size, img_size), device=device)  # init img\n",
    "_ = model(img) if device.type != 'cpu' else None  # run once\n",
    "\n",
    "\n",
    "\n",
    "for path, img, im0s, vid_cap in dataset:\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    t1 = time_synchronized()\n",
    "    pred = model(img, augment=False)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, conf_thres, iou_thres, agnostic=agnostic_nms)\n",
    "    t2 = time_synchronized()\n",
    "    \n",
    "    # Process detections\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        if webcam:  # batch_size >= 1\n",
    "            p, s, im0 = path[i], '%g: ' % i, im0s[i].copy()\n",
    "        else:\n",
    "            p, s, im0 = path, '', im0s\n",
    "\n",
    "        save_path = str(Path(output) / Path(p).name)\n",
    "        txt_path = str(Path(output) / Path(p).stem) + ('_%g' % dataset.frame if dataset.mode == 'video' else '')\n",
    "        s += '%gx%g ' % img.shape[2:]  # print string\n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # Print results\n",
    "            for c in det[:, -1].detach().unique():\n",
    "                n = (det[:, -1] == c).sum()  # detections per class\n",
    "                s += '%g %ss, ' % (n, names[int(c)])  # add to string\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                if save_txt:  # Write to file\n",
    "                    xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                    with open(txt_path + '.txt', 'a') as f:\n",
    "                        f.write(('%g ' * 5 + '\\n') % (cls, *xywh))  # label format\n",
    "\n",
    "                if save_img or view_img:  # Add bbox to image\n",
    "                    label = '%s %.2f' % (names[int(cls)], conf)\n",
    "                    plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=3)\n",
    "\n",
    "        # Print time (inference + NMS)\n",
    "        print('%sDone. (%.3fs)' % (s, t2 - t1))\n",
    "\n",
    "        # Stream results\n",
    "        if view_img:\n",
    "            cv2.imshow(p, im0)\n",
    "            if cv2.waitKey(1) == ord('q'):  # q to quit\n",
    "                raise StopIteration\n",
    "\n",
    "        # Save results (image with detections)\n",
    "        if save_img:\n",
    "            if dataset.mode == 'images':\n",
    "                cv2.imwrite(save_path, im0)\n",
    "            else:\n",
    "                if vid_path != save_path:  # new video\n",
    "                    vid_path = save_path\n",
    "                    if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                        vid_writer.release()  # release previous video writer\n",
    "\n",
    "                    fourcc = 'mp4v'  # output video codec\n",
    "                    fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                    w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                    h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*fourcc), fps, (w, h))\n",
    "                vid_writer.write(im0)\n",
    "    if save_txt or save_img:\n",
    "        print('Results saved to %s' % Path(output))\n",
    "        \n",
    "    print('Done. (%.3fs)' % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-reviewer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
